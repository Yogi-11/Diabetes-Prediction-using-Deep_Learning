{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Hvum-hlRNd9I"
      },
      "outputs": [],
      "source": [
        "\n",
        "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qQelf1trNd9K"
      },
      "outputs": [],
      "source": [
        "# Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qJ-ilrJFNd9L"
      },
      "outputs": [],
      "source": [
        "##Load in the data set (Internet Access needed)\n",
        "\n",
        "diabetes_df = pd.read_csv('kaggle_diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "cDfHqGm-Nd9M",
        "outputId": "b06146da-7b1e-4541-bc09-b5f60f44c330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "1659            4      115             72              0        0  28.9   \n",
              "1840            3      108             62             24        0  26.0   \n",
              "1383            1       87             78             27       32  34.6   \n",
              "591             2      112             78             50      140  39.4   \n",
              "1261            1       81             72             18       40  26.6   \n",
              "\n",
              "      DiabetesPedigreeFunction  Age  Outcome  \n",
              "1659                     0.376   46        1  \n",
              "1840                     0.223   25        0  \n",
              "1383                     0.101   22        0  \n",
              "591                      0.175   24        0  \n",
              "1261                     0.283   24        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-caecdc47-c511-419d-bbbe-a81839763e07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1659</th>\n",
              "      <td>4</td>\n",
              "      <td>115</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0.376</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1840</th>\n",
              "      <td>3</td>\n",
              "      <td>108</td>\n",
              "      <td>62</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.223</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1383</th>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>78</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>34.6</td>\n",
              "      <td>0.101</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>2</td>\n",
              "      <td>112</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>140</td>\n",
              "      <td>39.4</td>\n",
              "      <td>0.175</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1261</th>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>72</td>\n",
              "      <td>18</td>\n",
              "      <td>40</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.283</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caecdc47-c511-419d-bbbe-a81839763e07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-caecdc47-c511-419d-bbbe-a81839763e07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-caecdc47-c511-419d-bbbe-a81839763e07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Take a peek at the data -- if there are lots of \"NaN\" we may have internet connectivity issues\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SMlBDYYLNd9M"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"Outcome\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1PrlXbZCNd9N"
      },
      "outputs": [],
      "source": [
        "# Split the data to Train, and Test (75%, 25%)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQqFqEMLNd9Q"
      },
      "source": [
        "## Building a Single Hidden Layer Neural Network\n",
        "\n",
        "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "q7tvSjU6Nd9R"
      },
      "outputs": [],
      "source": [
        "# First let's normalize the data\n",
        "# This aids the training of neural nets by providing numerical stability\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "pXw67K2ONd9R"
      },
      "outputs": [],
      "source": [
        "# Define the Model \n",
        "# Input size is 8-dimensional\n",
        "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "model_1 = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5ZawF12Nd9R",
        "outputId": "0ea91cb0-c960-47c6-cdc7-7b5df4ea9823",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 12)                108       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#  This is a nice tool to view the model we have created and count the parameters\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dACVrY-fNd9R"
      },
      "source": [
        "Fitting model for model 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vvwx_Q-Nd9S",
        "outputId": "dd0f0b25-baef-43ad-a0c8-96315989fb71",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 1s 6ms/step - loss: 0.5865 - accuracy: 0.7293 - val_loss: 0.4919 - val_accuracy: 0.7860\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7567 - val_loss: 0.4539 - val_accuracy: 0.7760\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7647 - val_loss: 0.4401 - val_accuracy: 0.7940\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7647 - val_loss: 0.4317 - val_accuracy: 0.7920\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7753 - val_loss: 0.4275 - val_accuracy: 0.8020\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7787 - val_loss: 0.4246 - val_accuracy: 0.8020\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7813 - val_loss: 0.4226 - val_accuracy: 0.8020\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7840 - val_loss: 0.4198 - val_accuracy: 0.8020\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7833 - val_loss: 0.4173 - val_accuracy: 0.8120\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7820 - val_loss: 0.4177 - val_accuracy: 0.8020\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7840 - val_loss: 0.4157 - val_accuracy: 0.8060\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7840 - val_loss: 0.4152 - val_accuracy: 0.8040\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7900 - val_loss: 0.4143 - val_accuracy: 0.8020\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7880 - val_loss: 0.4127 - val_accuracy: 0.8060\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7887 - val_loss: 0.4120 - val_accuracy: 0.8100\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7900 - val_loss: 0.4113 - val_accuracy: 0.8060\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7880 - val_loss: 0.4111 - val_accuracy: 0.8100\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7880 - val_loss: 0.4092 - val_accuracy: 0.8100\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7893 - val_loss: 0.4096 - val_accuracy: 0.8100\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7920 - val_loss: 0.4062 - val_accuracy: 0.8120\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7953 - val_loss: 0.4069 - val_accuracy: 0.8200\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7993 - val_loss: 0.4052 - val_accuracy: 0.8140\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8013 - val_loss: 0.4044 - val_accuracy: 0.8140\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8020 - val_loss: 0.4020 - val_accuracy: 0.8140\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8013 - val_loss: 0.4026 - val_accuracy: 0.8180\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8067 - val_loss: 0.4025 - val_accuracy: 0.8200\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8020 - val_loss: 0.4006 - val_accuracy: 0.8240\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8100 - val_loss: 0.4010 - val_accuracy: 0.8220\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8027 - val_loss: 0.4026 - val_accuracy: 0.8240\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8060 - val_loss: 0.4017 - val_accuracy: 0.8180\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8080 - val_loss: 0.3995 - val_accuracy: 0.8280\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8047 - val_loss: 0.3992 - val_accuracy: 0.8280\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8140 - val_loss: 0.3991 - val_accuracy: 0.8280\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8107 - val_loss: 0.3982 - val_accuracy: 0.8320\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8127 - val_loss: 0.3983 - val_accuracy: 0.8260\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8127 - val_loss: 0.3964 - val_accuracy: 0.8260\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8140 - val_loss: 0.3964 - val_accuracy: 0.8300\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8167 - val_loss: 0.3957 - val_accuracy: 0.8260\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8087 - val_loss: 0.3962 - val_accuracy: 0.8300\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8160 - val_loss: 0.3967 - val_accuracy: 0.8280\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8173 - val_loss: 0.3956 - val_accuracy: 0.8300\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8113 - val_loss: 0.3955 - val_accuracy: 0.8260\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8180 - val_loss: 0.3955 - val_accuracy: 0.8320\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8140 - val_loss: 0.3955 - val_accuracy: 0.8280\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8153 - val_loss: 0.3943 - val_accuracy: 0.8300\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8147 - val_loss: 0.3934 - val_accuracy: 0.8300\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8147 - val_loss: 0.3925 - val_accuracy: 0.8240\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8187 - val_loss: 0.3921 - val_accuracy: 0.8280\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8127 - val_loss: 0.3927 - val_accuracy: 0.8340\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8167 - val_loss: 0.3939 - val_accuracy: 0.8280\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8173 - val_loss: 0.3917 - val_accuracy: 0.8260\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8213 - val_loss: 0.3917 - val_accuracy: 0.8300\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8213 - val_loss: 0.3898 - val_accuracy: 0.8240\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.3892 - val_accuracy: 0.8300\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8180 - val_loss: 0.3908 - val_accuracy: 0.8300\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8200 - val_loss: 0.3916 - val_accuracy: 0.8220\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8187 - val_loss: 0.3903 - val_accuracy: 0.8320\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8207 - val_loss: 0.3903 - val_accuracy: 0.8260\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8227 - val_loss: 0.3890 - val_accuracy: 0.8280\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8187 - val_loss: 0.3892 - val_accuracy: 0.8220\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8167 - val_loss: 0.3880 - val_accuracy: 0.8300\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8253 - val_loss: 0.3868 - val_accuracy: 0.8300\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8187 - val_loss: 0.3888 - val_accuracy: 0.8280\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8193 - val_loss: 0.3863 - val_accuracy: 0.8280\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8227 - val_loss: 0.3869 - val_accuracy: 0.8280\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8233 - val_loss: 0.3883 - val_accuracy: 0.8240\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8200 - val_loss: 0.3869 - val_accuracy: 0.8260\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8227 - val_loss: 0.3867 - val_accuracy: 0.8240\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8207 - val_loss: 0.3851 - val_accuracy: 0.8300\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8267 - val_loss: 0.3849 - val_accuracy: 0.8280\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8233 - val_loss: 0.3855 - val_accuracy: 0.8240\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8247 - val_loss: 0.3874 - val_accuracy: 0.8220\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8213 - val_loss: 0.3868 - val_accuracy: 0.8220\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8233 - val_loss: 0.3858 - val_accuracy: 0.8260\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8160 - val_loss: 0.3850 - val_accuracy: 0.8280\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8227 - val_loss: 0.3859 - val_accuracy: 0.8220\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8240 - val_loss: 0.3862 - val_accuracy: 0.8240\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8227 - val_loss: 0.3856 - val_accuracy: 0.8220\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8240 - val_loss: 0.3862 - val_accuracy: 0.8220\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8247 - val_loss: 0.3855 - val_accuracy: 0.8280\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8220 - val_loss: 0.3843 - val_accuracy: 0.8260\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8220 - val_loss: 0.3847 - val_accuracy: 0.8200\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8213 - val_loss: 0.3841 - val_accuracy: 0.8280\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8247 - val_loss: 0.3849 - val_accuracy: 0.8220\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8227 - val_loss: 0.3856 - val_accuracy: 0.8240\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8187 - val_loss: 0.3845 - val_accuracy: 0.8200\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8233 - val_loss: 0.3847 - val_accuracy: 0.8220\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8207 - val_loss: 0.3843 - val_accuracy: 0.8240\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8167 - val_loss: 0.3826 - val_accuracy: 0.8260\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8180 - val_loss: 0.3844 - val_accuracy: 0.8260\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8213 - val_loss: 0.3836 - val_accuracy: 0.8220\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8253 - val_loss: 0.3830 - val_accuracy: 0.8220\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8220 - val_loss: 0.3837 - val_accuracy: 0.8260\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8207 - val_loss: 0.3835 - val_accuracy: 0.8260\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8173 - val_loss: 0.3845 - val_accuracy: 0.8280\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8233 - val_loss: 0.3835 - val_accuracy: 0.8220\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8253 - val_loss: 0.3835 - val_accuracy: 0.8260\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8213 - val_loss: 0.3832 - val_accuracy: 0.8260\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8233 - val_loss: 0.3855 - val_accuracy: 0.8300\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8260 - val_loss: 0.3842 - val_accuracy: 0.8300\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8247 - val_loss: 0.3857 - val_accuracy: 0.8300\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8227 - val_loss: 0.3831 - val_accuracy: 0.8260\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8227 - val_loss: 0.3821 - val_accuracy: 0.8260\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8233 - val_loss: 0.3838 - val_accuracy: 0.8240\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8233 - val_loss: 0.3831 - val_accuracy: 0.8220\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8213 - val_loss: 0.3839 - val_accuracy: 0.8260\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8220 - val_loss: 0.3820 - val_accuracy: 0.8320\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8180 - val_loss: 0.3823 - val_accuracy: 0.8240\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8213 - val_loss: 0.3824 - val_accuracy: 0.8300\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8213 - val_loss: 0.3831 - val_accuracy: 0.8340\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8260 - val_loss: 0.3826 - val_accuracy: 0.8340\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8220 - val_loss: 0.3811 - val_accuracy: 0.8280\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8207 - val_loss: 0.3824 - val_accuracy: 0.8240\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8193 - val_loss: 0.3836 - val_accuracy: 0.8220\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8220 - val_loss: 0.3832 - val_accuracy: 0.8220\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8213 - val_loss: 0.3824 - val_accuracy: 0.8340\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8267 - val_loss: 0.3808 - val_accuracy: 0.8280\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8253 - val_loss: 0.3833 - val_accuracy: 0.8200\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8193 - val_loss: 0.3819 - val_accuracy: 0.8340\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8240 - val_loss: 0.3812 - val_accuracy: 0.8360\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8193 - val_loss: 0.3846 - val_accuracy: 0.8180\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8240 - val_loss: 0.3817 - val_accuracy: 0.8300\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8233 - val_loss: 0.3810 - val_accuracy: 0.8320\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8247 - val_loss: 0.3819 - val_accuracy: 0.8260\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8233 - val_loss: 0.3823 - val_accuracy: 0.8260\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8247 - val_loss: 0.3824 - val_accuracy: 0.8400\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8247 - val_loss: 0.3818 - val_accuracy: 0.8300\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8300 - val_loss: 0.3801 - val_accuracy: 0.8340\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8247 - val_loss: 0.3830 - val_accuracy: 0.8180\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8233 - val_loss: 0.3815 - val_accuracy: 0.8280\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8180 - val_loss: 0.3808 - val_accuracy: 0.8420\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8207 - val_loss: 0.3827 - val_accuracy: 0.8320\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8307 - val_loss: 0.3809 - val_accuracy: 0.8300\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8240 - val_loss: 0.3813 - val_accuracy: 0.8260\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8253 - val_loss: 0.3812 - val_accuracy: 0.8300\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8280 - val_loss: 0.3834 - val_accuracy: 0.8300\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8213 - val_loss: 0.3827 - val_accuracy: 0.8140\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8227 - val_loss: 0.3821 - val_accuracy: 0.8200\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8207 - val_loss: 0.3806 - val_accuracy: 0.8440\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8247 - val_loss: 0.3811 - val_accuracy: 0.8280\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8247 - val_loss: 0.3797 - val_accuracy: 0.8340\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8253 - val_loss: 0.3804 - val_accuracy: 0.8220\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8273 - val_loss: 0.3800 - val_accuracy: 0.8320\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8280 - val_loss: 0.3803 - val_accuracy: 0.8240\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8280 - val_loss: 0.3801 - val_accuracy: 0.8280\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8260 - val_loss: 0.3808 - val_accuracy: 0.8340\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8267 - val_loss: 0.3801 - val_accuracy: 0.8480\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8267 - val_loss: 0.3811 - val_accuracy: 0.8240\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8273 - val_loss: 0.3810 - val_accuracy: 0.8340\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8253 - val_loss: 0.3792 - val_accuracy: 0.8320\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8340 - val_loss: 0.3816 - val_accuracy: 0.8280\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8207 - val_loss: 0.3810 - val_accuracy: 0.8340\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8280 - val_loss: 0.3815 - val_accuracy: 0.8240\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8260 - val_loss: 0.3804 - val_accuracy: 0.8420\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8253 - val_loss: 0.3817 - val_accuracy: 0.8240\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8260 - val_loss: 0.3833 - val_accuracy: 0.8300\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8293 - val_loss: 0.3804 - val_accuracy: 0.8420\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8247 - val_loss: 0.3810 - val_accuracy: 0.8260\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8267 - val_loss: 0.3780 - val_accuracy: 0.8480\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8287 - val_loss: 0.3811 - val_accuracy: 0.8300\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8233 - val_loss: 0.3817 - val_accuracy: 0.8420\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8253 - val_loss: 0.3798 - val_accuracy: 0.8480\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8240 - val_loss: 0.3814 - val_accuracy: 0.8280\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8213 - val_loss: 0.3819 - val_accuracy: 0.8300\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8260 - val_loss: 0.3875 - val_accuracy: 0.8180\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8207 - val_loss: 0.3801 - val_accuracy: 0.8400\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8293 - val_loss: 0.3829 - val_accuracy: 0.8180\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8193 - val_loss: 0.3811 - val_accuracy: 0.8340\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8233 - val_loss: 0.3805 - val_accuracy: 0.8440\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8207 - val_loss: 0.3797 - val_accuracy: 0.8280\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8233 - val_loss: 0.3795 - val_accuracy: 0.8280\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8247 - val_loss: 0.3796 - val_accuracy: 0.8340\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8240 - val_loss: 0.3809 - val_accuracy: 0.8300\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8240 - val_loss: 0.3856 - val_accuracy: 0.8160\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8220 - val_loss: 0.3812 - val_accuracy: 0.8400\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8233 - val_loss: 0.3799 - val_accuracy: 0.8320\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8227 - val_loss: 0.3804 - val_accuracy: 0.8380\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8293 - val_loss: 0.3824 - val_accuracy: 0.8180\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8307 - val_loss: 0.3799 - val_accuracy: 0.8380\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8287 - val_loss: 0.3818 - val_accuracy: 0.8320\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8273 - val_loss: 0.3808 - val_accuracy: 0.8240\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8280 - val_loss: 0.3815 - val_accuracy: 0.8380\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8260 - val_loss: 0.3788 - val_accuracy: 0.8460\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8280 - val_loss: 0.3808 - val_accuracy: 0.8260\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8227 - val_loss: 0.3803 - val_accuracy: 0.8400\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8247 - val_loss: 0.3801 - val_accuracy: 0.8440\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8280 - val_loss: 0.3796 - val_accuracy: 0.8360\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8280 - val_loss: 0.3795 - val_accuracy: 0.8420\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8247 - val_loss: 0.3808 - val_accuracy: 0.8420\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8320 - val_loss: 0.3789 - val_accuracy: 0.8380\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8193 - val_loss: 0.3788 - val_accuracy: 0.8320\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8213 - val_loss: 0.3796 - val_accuracy: 0.8260\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8247 - val_loss: 0.3804 - val_accuracy: 0.8380\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8227 - val_loss: 0.3794 - val_accuracy: 0.8340\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8247 - val_loss: 0.3791 - val_accuracy: 0.8360\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8200 - val_loss: 0.3789 - val_accuracy: 0.8320\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8227 - val_loss: 0.3815 - val_accuracy: 0.8300\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8213 - val_loss: 0.3803 - val_accuracy: 0.8380\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8233 - val_loss: 0.3790 - val_accuracy: 0.8400\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8233 - val_loss: 0.3795 - val_accuracy: 0.8320\n"
          ]
        }
      ],
      "source": [
        "# Fit(Train) the Model\n",
        "\n",
        "# Compile the model with Optimizer, Loss Function and Metrics\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model_1.compile(Adam(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "IhkM_4b6Nd9S"
      },
      "outputs": [],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwzI8bslNd9T",
        "outputId": "d23558e5-98b6-4213-eb2c-21b249121039"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.67238986],\n",
              "       [0.06043518],\n",
              "       [0.26677164],\n",
              "       [0.02302974],\n",
              "       [0.00200754],\n",
              "       [0.29695058],\n",
              "       [0.1095871 ],\n",
              "       [0.48310316],\n",
              "       [0.05762175],\n",
              "       [0.65323824]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STXcpqTONd9T"
      },
      "source": [
        "There may be some variation in exact numbers due to randomness, but we should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-5iLIsnNd9T"
      },
      "source": [
        "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q2D3eJkNd9T",
        "outputId": "13651076-e570-423e-c030-cc06f5756261"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpbkTA-VNd9U"
      },
      "source": [
        "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "B0NpoLXENd9U",
        "outputId": "70fbe8f4-25e1-4214-fd50-e07e0220d188",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ffa35e70b50>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMU2Y42UNd9U"
      },
      "source": [
        "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEj69Mr6Nd9U",
        "scrolled": true,
        "outputId": "36c800f1-a218-4c9d-c6dc-f1431caddd98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8180 - val_loss: 0.3804 - val_accuracy: 0.8400\n",
            "Epoch 2/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8247 - val_loss: 0.3792 - val_accuracy: 0.8320\n",
            "Epoch 3/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8267 - val_loss: 0.3816 - val_accuracy: 0.8140\n",
            "Epoch 4/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8180 - val_loss: 0.3798 - val_accuracy: 0.8160\n",
            "Epoch 5/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8180 - val_loss: 0.3779 - val_accuracy: 0.8400\n",
            "Epoch 6/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8253 - val_loss: 0.3824 - val_accuracy: 0.8120\n",
            "Epoch 7/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8213 - val_loss: 0.3790 - val_accuracy: 0.8400\n",
            "Epoch 8/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8260 - val_loss: 0.3796 - val_accuracy: 0.8400\n",
            "Epoch 9/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8240 - val_loss: 0.3799 - val_accuracy: 0.8300\n",
            "Epoch 10/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8240 - val_loss: 0.3804 - val_accuracy: 0.8200\n",
            "Epoch 11/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8193 - val_loss: 0.3793 - val_accuracy: 0.8460\n",
            "Epoch 12/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8260 - val_loss: 0.3802 - val_accuracy: 0.8340\n",
            "Epoch 13/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8213 - val_loss: 0.3822 - val_accuracy: 0.8260\n",
            "Epoch 14/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8200 - val_loss: 0.3793 - val_accuracy: 0.8340\n",
            "Epoch 15/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8220 - val_loss: 0.3789 - val_accuracy: 0.8300\n",
            "Epoch 16/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8220 - val_loss: 0.3789 - val_accuracy: 0.8280\n",
            "Epoch 17/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8227 - val_loss: 0.3794 - val_accuracy: 0.8400\n",
            "Epoch 18/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8220 - val_loss: 0.3802 - val_accuracy: 0.8320\n",
            "Epoch 19/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8187 - val_loss: 0.3789 - val_accuracy: 0.8280\n",
            "Epoch 20/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8207 - val_loss: 0.3775 - val_accuracy: 0.8320\n",
            "Epoch 21/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8187 - val_loss: 0.3787 - val_accuracy: 0.8280\n",
            "Epoch 22/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8240 - val_loss: 0.3784 - val_accuracy: 0.8460\n",
            "Epoch 23/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8273 - val_loss: 0.3808 - val_accuracy: 0.8180\n",
            "Epoch 24/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8253 - val_loss: 0.3810 - val_accuracy: 0.8220\n",
            "Epoch 25/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8233 - val_loss: 0.3776 - val_accuracy: 0.8320\n",
            "Epoch 26/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8213 - val_loss: 0.3793 - val_accuracy: 0.8400\n",
            "Epoch 27/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8300 - val_loss: 0.3787 - val_accuracy: 0.8280\n",
            "Epoch 28/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8260 - val_loss: 0.3774 - val_accuracy: 0.8460\n",
            "Epoch 29/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8247 - val_loss: 0.3791 - val_accuracy: 0.8380\n",
            "Epoch 30/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8213 - val_loss: 0.3774 - val_accuracy: 0.8400\n",
            "Epoch 31/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8220 - val_loss: 0.3777 - val_accuracy: 0.8440\n",
            "Epoch 32/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8300 - val_loss: 0.3791 - val_accuracy: 0.8240\n",
            "Epoch 33/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8207 - val_loss: 0.3760 - val_accuracy: 0.8400\n",
            "Epoch 34/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8273 - val_loss: 0.3772 - val_accuracy: 0.8420\n",
            "Epoch 35/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8300 - val_loss: 0.3773 - val_accuracy: 0.8320\n",
            "Epoch 36/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8247 - val_loss: 0.3767 - val_accuracy: 0.8360\n",
            "Epoch 37/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8233 - val_loss: 0.3801 - val_accuracy: 0.8240\n",
            "Epoch 38/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8240 - val_loss: 0.3770 - val_accuracy: 0.8300\n",
            "Epoch 39/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8227 - val_loss: 0.3772 - val_accuracy: 0.8280\n",
            "Epoch 40/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8193 - val_loss: 0.3763 - val_accuracy: 0.8440\n",
            "Epoch 41/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8240 - val_loss: 0.3763 - val_accuracy: 0.8400\n",
            "Epoch 42/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8287 - val_loss: 0.3768 - val_accuracy: 0.8440\n",
            "Epoch 43/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8260 - val_loss: 0.3755 - val_accuracy: 0.8440\n",
            "Epoch 44/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8260 - val_loss: 0.3764 - val_accuracy: 0.8300\n",
            "Epoch 45/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8253 - val_loss: 0.3757 - val_accuracy: 0.8300\n",
            "Epoch 46/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8213 - val_loss: 0.3796 - val_accuracy: 0.8280\n",
            "Epoch 47/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8253 - val_loss: 0.3757 - val_accuracy: 0.8440\n",
            "Epoch 48/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8247 - val_loss: 0.3775 - val_accuracy: 0.8260\n",
            "Epoch 49/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8207 - val_loss: 0.3747 - val_accuracy: 0.8380\n",
            "Epoch 50/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8200 - val_loss: 0.3756 - val_accuracy: 0.8260\n",
            "Epoch 51/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8193 - val_loss: 0.3745 - val_accuracy: 0.8280\n",
            "Epoch 52/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8240 - val_loss: 0.3748 - val_accuracy: 0.8400\n",
            "Epoch 53/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8260 - val_loss: 0.3750 - val_accuracy: 0.8200\n",
            "Epoch 54/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8247 - val_loss: 0.3740 - val_accuracy: 0.8260\n",
            "Epoch 55/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8227 - val_loss: 0.3738 - val_accuracy: 0.8260\n",
            "Epoch 56/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8227 - val_loss: 0.3733 - val_accuracy: 0.8400\n",
            "Epoch 57/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8273 - val_loss: 0.3740 - val_accuracy: 0.8260\n",
            "Epoch 58/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8233 - val_loss: 0.3731 - val_accuracy: 0.8260\n",
            "Epoch 59/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8253 - val_loss: 0.3723 - val_accuracy: 0.8360\n",
            "Epoch 60/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8227 - val_loss: 0.3749 - val_accuracy: 0.8240\n",
            "Epoch 61/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8240 - val_loss: 0.3732 - val_accuracy: 0.8240\n",
            "Epoch 62/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8273 - val_loss: 0.3726 - val_accuracy: 0.8340\n",
            "Epoch 63/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8260 - val_loss: 0.3759 - val_accuracy: 0.8280\n",
            "Epoch 64/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8280 - val_loss: 0.3731 - val_accuracy: 0.8340\n",
            "Epoch 65/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8247 - val_loss: 0.3731 - val_accuracy: 0.8340\n",
            "Epoch 66/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.8307 - val_loss: 0.3736 - val_accuracy: 0.8520\n",
            "Epoch 67/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8313 - val_loss: 0.3746 - val_accuracy: 0.8300\n",
            "Epoch 68/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8220 - val_loss: 0.3726 - val_accuracy: 0.8480\n",
            "Epoch 69/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8300 - val_loss: 0.3729 - val_accuracy: 0.8340\n",
            "Epoch 70/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8253 - val_loss: 0.3755 - val_accuracy: 0.8200\n",
            "Epoch 71/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8313 - val_loss: 0.3730 - val_accuracy: 0.8380\n",
            "Epoch 72/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8300 - val_loss: 0.3714 - val_accuracy: 0.8400\n",
            "Epoch 73/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8273 - val_loss: 0.3729 - val_accuracy: 0.8360\n",
            "Epoch 74/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8247 - val_loss: 0.3743 - val_accuracy: 0.8280\n",
            "Epoch 75/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8247 - val_loss: 0.3719 - val_accuracy: 0.8340\n",
            "Epoch 76/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8307 - val_loss: 0.3702 - val_accuracy: 0.8360\n",
            "Epoch 77/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8260 - val_loss: 0.3711 - val_accuracy: 0.8380\n",
            "Epoch 78/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8313 - val_loss: 0.3725 - val_accuracy: 0.8360\n",
            "Epoch 79/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8253 - val_loss: 0.3696 - val_accuracy: 0.8340\n",
            "Epoch 80/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8280 - val_loss: 0.3705 - val_accuracy: 0.8420\n",
            "Epoch 81/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8320 - val_loss: 0.3688 - val_accuracy: 0.8440\n",
            "Epoch 82/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8273 - val_loss: 0.3683 - val_accuracy: 0.8440\n",
            "Epoch 83/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8213 - val_loss: 0.3703 - val_accuracy: 0.8300\n",
            "Epoch 84/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8267 - val_loss: 0.3680 - val_accuracy: 0.8360\n",
            "Epoch 85/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8253 - val_loss: 0.3697 - val_accuracy: 0.8340\n",
            "Epoch 86/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8240 - val_loss: 0.3696 - val_accuracy: 0.8340\n",
            "Epoch 87/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8240 - val_loss: 0.3693 - val_accuracy: 0.8320\n",
            "Epoch 88/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8307 - val_loss: 0.3684 - val_accuracy: 0.8360\n",
            "Epoch 89/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8233 - val_loss: 0.3685 - val_accuracy: 0.8360\n",
            "Epoch 90/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8300 - val_loss: 0.3670 - val_accuracy: 0.8440\n",
            "Epoch 91/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8267 - val_loss: 0.3664 - val_accuracy: 0.8400\n",
            "Epoch 92/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8293 - val_loss: 0.3693 - val_accuracy: 0.8360\n",
            "Epoch 93/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8247 - val_loss: 0.3668 - val_accuracy: 0.8360\n",
            "Epoch 94/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8220 - val_loss: 0.3673 - val_accuracy: 0.8400\n",
            "Epoch 95/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8260 - val_loss: 0.3672 - val_accuracy: 0.8380\n",
            "Epoch 96/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8260 - val_loss: 0.3666 - val_accuracy: 0.8440\n",
            "Epoch 97/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8280 - val_loss: 0.3652 - val_accuracy: 0.8480\n",
            "Epoch 98/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8293 - val_loss: 0.3648 - val_accuracy: 0.8420\n",
            "Epoch 99/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8220 - val_loss: 0.3657 - val_accuracy: 0.8360\n",
            "Epoch 100/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8273 - val_loss: 0.3668 - val_accuracy: 0.8420\n",
            "Epoch 101/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8267 - val_loss: 0.3649 - val_accuracy: 0.8380\n",
            "Epoch 102/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8273 - val_loss: 0.3656 - val_accuracy: 0.8440\n",
            "Epoch 103/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8207 - val_loss: 0.3642 - val_accuracy: 0.8360\n",
            "Epoch 104/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8200 - val_loss: 0.3634 - val_accuracy: 0.8360\n",
            "Epoch 105/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8253 - val_loss: 0.3651 - val_accuracy: 0.8340\n",
            "Epoch 106/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8247 - val_loss: 0.3652 - val_accuracy: 0.8400\n",
            "Epoch 107/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8227 - val_loss: 0.3641 - val_accuracy: 0.8380\n",
            "Epoch 108/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8200 - val_loss: 0.3644 - val_accuracy: 0.8380\n",
            "Epoch 109/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8293 - val_loss: 0.3638 - val_accuracy: 0.8440\n",
            "Epoch 110/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8280 - val_loss: 0.3633 - val_accuracy: 0.8460\n",
            "Epoch 111/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8273 - val_loss: 0.3641 - val_accuracy: 0.8360\n",
            "Epoch 112/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8320 - val_loss: 0.3651 - val_accuracy: 0.8320\n",
            "Epoch 113/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8233 - val_loss: 0.3640 - val_accuracy: 0.8420\n",
            "Epoch 114/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8280 - val_loss: 0.3645 - val_accuracy: 0.8340\n",
            "Epoch 115/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8280 - val_loss: 0.3624 - val_accuracy: 0.8420\n",
            "Epoch 116/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8273 - val_loss: 0.3647 - val_accuracy: 0.8360\n",
            "Epoch 117/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8267 - val_loss: 0.3632 - val_accuracy: 0.8420\n",
            "Epoch 118/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8240 - val_loss: 0.3631 - val_accuracy: 0.8420\n",
            "Epoch 119/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8220 - val_loss: 0.3622 - val_accuracy: 0.8440\n",
            "Epoch 120/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8260 - val_loss: 0.3631 - val_accuracy: 0.8380\n",
            "Epoch 121/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8287 - val_loss: 0.3612 - val_accuracy: 0.8420\n",
            "Epoch 122/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8287 - val_loss: 0.3640 - val_accuracy: 0.8440\n",
            "Epoch 123/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8287 - val_loss: 0.3611 - val_accuracy: 0.8420\n",
            "Epoch 124/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8227 - val_loss: 0.3620 - val_accuracy: 0.8400\n",
            "Epoch 125/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8287 - val_loss: 0.3606 - val_accuracy: 0.8400\n",
            "Epoch 126/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8327 - val_loss: 0.3616 - val_accuracy: 0.8380\n",
            "Epoch 127/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8253 - val_loss: 0.3608 - val_accuracy: 0.8420\n",
            "Epoch 128/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8313 - val_loss: 0.3592 - val_accuracy: 0.8420\n",
            "Epoch 129/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8180 - val_loss: 0.3596 - val_accuracy: 0.8360\n",
            "Epoch 130/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8267 - val_loss: 0.3599 - val_accuracy: 0.8440\n",
            "Epoch 131/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8287 - val_loss: 0.3615 - val_accuracy: 0.8320\n",
            "Epoch 132/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8300 - val_loss: 0.3594 - val_accuracy: 0.8400\n",
            "Epoch 133/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8267 - val_loss: 0.3589 - val_accuracy: 0.8460\n",
            "Epoch 134/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8273 - val_loss: 0.3603 - val_accuracy: 0.8380\n",
            "Epoch 135/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8360 - val_loss: 0.3595 - val_accuracy: 0.8460\n",
            "Epoch 136/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8287 - val_loss: 0.3590 - val_accuracy: 0.8400\n",
            "Epoch 137/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8293 - val_loss: 0.3591 - val_accuracy: 0.8460\n",
            "Epoch 138/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8273 - val_loss: 0.3597 - val_accuracy: 0.8360\n",
            "Epoch 139/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8253 - val_loss: 0.3595 - val_accuracy: 0.8380\n",
            "Epoch 140/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8327 - val_loss: 0.3584 - val_accuracy: 0.8400\n",
            "Epoch 141/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8313 - val_loss: 0.3576 - val_accuracy: 0.8440\n",
            "Epoch 142/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8300 - val_loss: 0.3590 - val_accuracy: 0.8400\n",
            "Epoch 143/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8280 - val_loss: 0.3579 - val_accuracy: 0.8340\n",
            "Epoch 144/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8340 - val_loss: 0.3578 - val_accuracy: 0.8440\n",
            "Epoch 145/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8347 - val_loss: 0.3578 - val_accuracy: 0.8340\n",
            "Epoch 146/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8347 - val_loss: 0.3584 - val_accuracy: 0.8380\n",
            "Epoch 147/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8333 - val_loss: 0.3599 - val_accuracy: 0.8360\n",
            "Epoch 148/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8327 - val_loss: 0.3576 - val_accuracy: 0.8420\n",
            "Epoch 149/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8280 - val_loss: 0.3597 - val_accuracy: 0.8360\n",
            "Epoch 150/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8327 - val_loss: 0.3586 - val_accuracy: 0.8400\n",
            "Epoch 151/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8253 - val_loss: 0.3591 - val_accuracy: 0.8320\n",
            "Epoch 152/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8293 - val_loss: 0.3576 - val_accuracy: 0.8340\n",
            "Epoch 153/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8333 - val_loss: 0.3575 - val_accuracy: 0.8380\n",
            "Epoch 154/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8373 - val_loss: 0.3587 - val_accuracy: 0.8460\n",
            "Epoch 155/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8287 - val_loss: 0.3568 - val_accuracy: 0.8380\n",
            "Epoch 156/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8307 - val_loss: 0.3582 - val_accuracy: 0.8380\n",
            "Epoch 157/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8307 - val_loss: 0.3579 - val_accuracy: 0.8300\n",
            "Epoch 158/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8300 - val_loss: 0.3570 - val_accuracy: 0.8420\n",
            "Epoch 159/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8320 - val_loss: 0.3597 - val_accuracy: 0.8400\n",
            "Epoch 160/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8293 - val_loss: 0.3600 - val_accuracy: 0.8380\n",
            "Epoch 161/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8307 - val_loss: 0.3581 - val_accuracy: 0.8380\n",
            "Epoch 162/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8320 - val_loss: 0.3593 - val_accuracy: 0.8320\n",
            "Epoch 163/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8293 - val_loss: 0.3585 - val_accuracy: 0.8380\n",
            "Epoch 164/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8307 - val_loss: 0.3583 - val_accuracy: 0.8440\n",
            "Epoch 165/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8353 - val_loss: 0.3574 - val_accuracy: 0.8400\n",
            "Epoch 166/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8300 - val_loss: 0.3582 - val_accuracy: 0.8300\n",
            "Epoch 167/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8360 - val_loss: 0.3586 - val_accuracy: 0.8400\n",
            "Epoch 168/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8327 - val_loss: 0.3587 - val_accuracy: 0.8340\n",
            "Epoch 169/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8333 - val_loss: 0.3582 - val_accuracy: 0.8440\n",
            "Epoch 170/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8260 - val_loss: 0.3606 - val_accuracy: 0.8320\n",
            "Epoch 171/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8333 - val_loss: 0.3581 - val_accuracy: 0.8340\n",
            "Epoch 172/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8267 - val_loss: 0.3599 - val_accuracy: 0.8360\n",
            "Epoch 173/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8360 - val_loss: 0.3574 - val_accuracy: 0.8300\n",
            "Epoch 174/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8320 - val_loss: 0.3588 - val_accuracy: 0.8380\n",
            "Epoch 175/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8293 - val_loss: 0.3581 - val_accuracy: 0.8380\n",
            "Epoch 176/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8347 - val_loss: 0.3583 - val_accuracy: 0.8380\n",
            "Epoch 177/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8340 - val_loss: 0.3625 - val_accuracy: 0.8400\n",
            "Epoch 178/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8313 - val_loss: 0.3584 - val_accuracy: 0.8320\n",
            "Epoch 179/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8320 - val_loss: 0.3587 - val_accuracy: 0.8380\n",
            "Epoch 180/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8313 - val_loss: 0.3581 - val_accuracy: 0.8360\n",
            "Epoch 181/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8300 - val_loss: 0.3604 - val_accuracy: 0.8280\n",
            "Epoch 182/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8300 - val_loss: 0.3589 - val_accuracy: 0.8380\n",
            "Epoch 183/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8287 - val_loss: 0.3589 - val_accuracy: 0.8360\n",
            "Epoch 184/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8313 - val_loss: 0.3617 - val_accuracy: 0.8300\n",
            "Epoch 185/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8367 - val_loss: 0.3605 - val_accuracy: 0.8400\n",
            "Epoch 186/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8287 - val_loss: 0.3585 - val_accuracy: 0.8300\n",
            "Epoch 187/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8287 - val_loss: 0.3596 - val_accuracy: 0.8340\n",
            "Epoch 188/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8253 - val_loss: 0.3597 - val_accuracy: 0.8360\n",
            "Epoch 189/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8360 - val_loss: 0.3593 - val_accuracy: 0.8300\n",
            "Epoch 190/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8333 - val_loss: 0.3596 - val_accuracy: 0.8280\n",
            "Epoch 191/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8253 - val_loss: 0.3598 - val_accuracy: 0.8420\n",
            "Epoch 192/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8320 - val_loss: 0.3567 - val_accuracy: 0.8380\n",
            "Epoch 193/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8267 - val_loss: 0.3592 - val_accuracy: 0.8380\n",
            "Epoch 194/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8233 - val_loss: 0.3589 - val_accuracy: 0.8420\n",
            "Epoch 195/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8347 - val_loss: 0.3585 - val_accuracy: 0.8360\n",
            "Epoch 196/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8293 - val_loss: 0.3580 - val_accuracy: 0.8340\n",
            "Epoch 197/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8300 - val_loss: 0.3576 - val_accuracy: 0.8320\n",
            "Epoch 198/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8347 - val_loss: 0.3579 - val_accuracy: 0.8380\n",
            "Epoch 199/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8333 - val_loss: 0.3569 - val_accuracy: 0.8380\n",
            "Epoch 200/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8327 - val_loss: 0.3589 - val_accuracy: 0.8260\n",
            "Epoch 201/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8340 - val_loss: 0.3624 - val_accuracy: 0.8340\n",
            "Epoch 202/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8293 - val_loss: 0.3572 - val_accuracy: 0.8340\n",
            "Epoch 203/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8327 - val_loss: 0.3584 - val_accuracy: 0.8280\n",
            "Epoch 204/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8320 - val_loss: 0.3583 - val_accuracy: 0.8340\n",
            "Epoch 205/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8313 - val_loss: 0.3586 - val_accuracy: 0.8340\n",
            "Epoch 206/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8320 - val_loss: 0.3580 - val_accuracy: 0.8340\n",
            "Epoch 207/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8267 - val_loss: 0.3593 - val_accuracy: 0.8220\n",
            "Epoch 208/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8387 - val_loss: 0.3604 - val_accuracy: 0.8360\n",
            "Epoch 209/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8293 - val_loss: 0.3573 - val_accuracy: 0.8320\n",
            "Epoch 210/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8273 - val_loss: 0.3573 - val_accuracy: 0.8340\n",
            "Epoch 211/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8327 - val_loss: 0.3574 - val_accuracy: 0.8320\n",
            "Epoch 212/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8313 - val_loss: 0.3583 - val_accuracy: 0.8380\n",
            "Epoch 213/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8287 - val_loss: 0.3579 - val_accuracy: 0.8340\n",
            "Epoch 214/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8247 - val_loss: 0.3566 - val_accuracy: 0.8260\n",
            "Epoch 215/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8300 - val_loss: 0.3587 - val_accuracy: 0.8340\n",
            "Epoch 216/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8367 - val_loss: 0.3589 - val_accuracy: 0.8360\n",
            "Epoch 217/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8273 - val_loss: 0.3594 - val_accuracy: 0.8340\n",
            "Epoch 218/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8360 - val_loss: 0.3606 - val_accuracy: 0.8280\n",
            "Epoch 219/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8313 - val_loss: 0.3568 - val_accuracy: 0.8340\n",
            "Epoch 220/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8340 - val_loss: 0.3577 - val_accuracy: 0.8280\n",
            "Epoch 221/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8327 - val_loss: 0.3582 - val_accuracy: 0.8340\n",
            "Epoch 222/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8300 - val_loss: 0.3570 - val_accuracy: 0.8340\n",
            "Epoch 223/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8267 - val_loss: 0.3564 - val_accuracy: 0.8320\n",
            "Epoch 224/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8373 - val_loss: 0.3590 - val_accuracy: 0.8240\n",
            "Epoch 225/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8367 - val_loss: 0.3582 - val_accuracy: 0.8360\n",
            "Epoch 226/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8280 - val_loss: 0.3593 - val_accuracy: 0.8280\n",
            "Epoch 227/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8280 - val_loss: 0.3560 - val_accuracy: 0.8380\n",
            "Epoch 228/1000\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.3656 - accuracy: 0.8327 - val_loss: 0.3575 - val_accuracy: 0.8320\n",
            "Epoch 229/1000\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.3655 - accuracy: 0.8327 - val_loss: 0.3594 - val_accuracy: 0.8320\n",
            "Epoch 230/1000\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8327 - val_loss: 0.3588 - val_accuracy: 0.8360\n",
            "Epoch 231/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8347 - val_loss: 0.3575 - val_accuracy: 0.8300\n",
            "Epoch 232/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8313 - val_loss: 0.3580 - val_accuracy: 0.8360\n",
            "Epoch 233/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8380 - val_loss: 0.3586 - val_accuracy: 0.8400\n",
            "Epoch 234/1000\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.8293 - val_loss: 0.3582 - val_accuracy: 0.8320\n",
            "Epoch 235/1000\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 0.3639 - accuracy: 0.8253 - val_loss: 0.3577 - val_accuracy: 0.8340\n",
            "Epoch 236/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8340 - val_loss: 0.3574 - val_accuracy: 0.8260\n",
            "Epoch 237/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8313 - val_loss: 0.3573 - val_accuracy: 0.8360\n",
            "Epoch 238/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8353 - val_loss: 0.3601 - val_accuracy: 0.8360\n",
            "Epoch 239/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8313 - val_loss: 0.3585 - val_accuracy: 0.8320\n",
            "Epoch 240/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8367 - val_loss: 0.3581 - val_accuracy: 0.8360\n",
            "Epoch 241/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8373 - val_loss: 0.3592 - val_accuracy: 0.8320\n",
            "Epoch 242/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8400 - val_loss: 0.3587 - val_accuracy: 0.8400\n",
            "Epoch 243/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8333 - val_loss: 0.3567 - val_accuracy: 0.8320\n",
            "Epoch 244/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8313 - val_loss: 0.3581 - val_accuracy: 0.8360\n",
            "Epoch 245/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8347 - val_loss: 0.3593 - val_accuracy: 0.8340\n",
            "Epoch 246/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8293 - val_loss: 0.3576 - val_accuracy: 0.8400\n",
            "Epoch 247/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8353 - val_loss: 0.3570 - val_accuracy: 0.8360\n",
            "Epoch 248/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8340 - val_loss: 0.3600 - val_accuracy: 0.8360\n",
            "Epoch 249/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8313 - val_loss: 0.3611 - val_accuracy: 0.8340\n",
            "Epoch 250/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8360 - val_loss: 0.3591 - val_accuracy: 0.8260\n",
            "Epoch 251/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8307 - val_loss: 0.3591 - val_accuracy: 0.8400\n",
            "Epoch 252/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8380 - val_loss: 0.3588 - val_accuracy: 0.8340\n",
            "Epoch 253/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8327 - val_loss: 0.3598 - val_accuracy: 0.8380\n",
            "Epoch 254/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8360 - val_loss: 0.3584 - val_accuracy: 0.8280\n",
            "Epoch 255/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8353 - val_loss: 0.3599 - val_accuracy: 0.8260\n",
            "Epoch 256/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8313 - val_loss: 0.3576 - val_accuracy: 0.8340\n",
            "Epoch 257/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8333 - val_loss: 0.3582 - val_accuracy: 0.8360\n",
            "Epoch 258/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8393 - val_loss: 0.3597 - val_accuracy: 0.8340\n",
            "Epoch 259/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8347 - val_loss: 0.3577 - val_accuracy: 0.8360\n",
            "Epoch 260/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8387 - val_loss: 0.3574 - val_accuracy: 0.8320\n",
            "Epoch 261/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8353 - val_loss: 0.3603 - val_accuracy: 0.8280\n",
            "Epoch 262/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8373 - val_loss: 0.3580 - val_accuracy: 0.8320\n",
            "Epoch 263/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8360 - val_loss: 0.3595 - val_accuracy: 0.8320\n",
            "Epoch 264/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8367 - val_loss: 0.3598 - val_accuracy: 0.8300\n",
            "Epoch 265/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8380 - val_loss: 0.3592 - val_accuracy: 0.8340\n",
            "Epoch 266/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8347 - val_loss: 0.3599 - val_accuracy: 0.8340\n",
            "Epoch 267/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8360 - val_loss: 0.3582 - val_accuracy: 0.8360\n",
            "Epoch 268/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8393 - val_loss: 0.3589 - val_accuracy: 0.8300\n",
            "Epoch 269/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8313 - val_loss: 0.3587 - val_accuracy: 0.8320\n",
            "Epoch 270/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8333 - val_loss: 0.3624 - val_accuracy: 0.8300\n",
            "Epoch 271/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8373 - val_loss: 0.3566 - val_accuracy: 0.8300\n",
            "Epoch 272/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8367 - val_loss: 0.3567 - val_accuracy: 0.8320\n",
            "Epoch 273/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8353 - val_loss: 0.3569 - val_accuracy: 0.8360\n",
            "Epoch 274/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8380 - val_loss: 0.3586 - val_accuracy: 0.8280\n",
            "Epoch 275/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8353 - val_loss: 0.3592 - val_accuracy: 0.8280\n",
            "Epoch 276/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8360 - val_loss: 0.3576 - val_accuracy: 0.8320\n",
            "Epoch 277/1000\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3632 - accuracy: 0.8353 - val_loss: 0.3562 - val_accuracy: 0.8340\n",
            "Epoch 278/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 0.3637 - accuracy: 0.8433 - val_loss: 0.3571 - val_accuracy: 0.8380\n",
            "Epoch 279/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3619 - accuracy: 0.8360 - val_loss: 0.3576 - val_accuracy: 0.8320\n",
            "Epoch 280/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8387 - val_loss: 0.3571 - val_accuracy: 0.8320\n",
            "Epoch 281/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8353 - val_loss: 0.3590 - val_accuracy: 0.8360\n",
            "Epoch 282/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8360 - val_loss: 0.3559 - val_accuracy: 0.8360\n",
            "Epoch 283/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8393 - val_loss: 0.3560 - val_accuracy: 0.8320\n",
            "Epoch 284/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8433 - val_loss: 0.3577 - val_accuracy: 0.8340\n",
            "Epoch 285/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8347 - val_loss: 0.3589 - val_accuracy: 0.8340\n",
            "Epoch 286/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8360 - val_loss: 0.3576 - val_accuracy: 0.8380\n",
            "Epoch 287/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8333 - val_loss: 0.3578 - val_accuracy: 0.8280\n",
            "Epoch 288/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8367 - val_loss: 0.3563 - val_accuracy: 0.8260\n",
            "Epoch 289/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8407 - val_loss: 0.3576 - val_accuracy: 0.8360\n",
            "Epoch 290/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8360 - val_loss: 0.3567 - val_accuracy: 0.8380\n",
            "Epoch 291/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8400 - val_loss: 0.3583 - val_accuracy: 0.8320\n",
            "Epoch 292/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8340 - val_loss: 0.3560 - val_accuracy: 0.8360\n",
            "Epoch 293/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8373 - val_loss: 0.3559 - val_accuracy: 0.8420\n",
            "Epoch 294/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8353 - val_loss: 0.3566 - val_accuracy: 0.8340\n",
            "Epoch 295/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8387 - val_loss: 0.3573 - val_accuracy: 0.8360\n",
            "Epoch 296/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8360 - val_loss: 0.3575 - val_accuracy: 0.8300\n",
            "Epoch 297/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8287 - val_loss: 0.3584 - val_accuracy: 0.8360\n",
            "Epoch 298/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8353 - val_loss: 0.3544 - val_accuracy: 0.8300\n",
            "Epoch 299/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8353 - val_loss: 0.3570 - val_accuracy: 0.8360\n",
            "Epoch 300/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8327 - val_loss: 0.3601 - val_accuracy: 0.8360\n",
            "Epoch 301/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8340 - val_loss: 0.3570 - val_accuracy: 0.8360\n",
            "Epoch 302/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8380 - val_loss: 0.3595 - val_accuracy: 0.8300\n",
            "Epoch 303/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8347 - val_loss: 0.3590 - val_accuracy: 0.8240\n",
            "Epoch 304/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8380 - val_loss: 0.3568 - val_accuracy: 0.8300\n",
            "Epoch 305/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8400 - val_loss: 0.3580 - val_accuracy: 0.8340\n",
            "Epoch 306/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8360 - val_loss: 0.3589 - val_accuracy: 0.8300\n",
            "Epoch 307/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8353 - val_loss: 0.3583 - val_accuracy: 0.8280\n",
            "Epoch 308/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8347 - val_loss: 0.3577 - val_accuracy: 0.8380\n",
            "Epoch 309/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8353 - val_loss: 0.3592 - val_accuracy: 0.8280\n",
            "Epoch 310/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8387 - val_loss: 0.3581 - val_accuracy: 0.8280\n",
            "Epoch 311/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8300 - val_loss: 0.3584 - val_accuracy: 0.8360\n",
            "Epoch 312/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8387 - val_loss: 0.3579 - val_accuracy: 0.8340\n",
            "Epoch 313/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8360 - val_loss: 0.3588 - val_accuracy: 0.8280\n",
            "Epoch 314/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8367 - val_loss: 0.3568 - val_accuracy: 0.8340\n",
            "Epoch 315/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8333 - val_loss: 0.3582 - val_accuracy: 0.8360\n",
            "Epoch 316/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8387 - val_loss: 0.3569 - val_accuracy: 0.8420\n",
            "Epoch 317/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8380 - val_loss: 0.3596 - val_accuracy: 0.8320\n",
            "Epoch 318/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8347 - val_loss: 0.3577 - val_accuracy: 0.8380\n",
            "Epoch 319/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8340 - val_loss: 0.3596 - val_accuracy: 0.8340\n",
            "Epoch 320/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8427 - val_loss: 0.3580 - val_accuracy: 0.8320\n",
            "Epoch 321/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8340 - val_loss: 0.3577 - val_accuracy: 0.8380\n",
            "Epoch 322/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8400 - val_loss: 0.3601 - val_accuracy: 0.8280\n",
            "Epoch 323/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8353 - val_loss: 0.3586 - val_accuracy: 0.8300\n",
            "Epoch 324/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8333 - val_loss: 0.3578 - val_accuracy: 0.8360\n",
            "Epoch 325/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8347 - val_loss: 0.3590 - val_accuracy: 0.8320\n",
            "Epoch 326/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8353 - val_loss: 0.3590 - val_accuracy: 0.8320\n",
            "Epoch 327/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8347 - val_loss: 0.3582 - val_accuracy: 0.8360\n",
            "Epoch 328/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8360 - val_loss: 0.3571 - val_accuracy: 0.8340\n",
            "Epoch 329/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8307 - val_loss: 0.3577 - val_accuracy: 0.8300\n",
            "Epoch 330/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8300 - val_loss: 0.3598 - val_accuracy: 0.8300\n",
            "Epoch 331/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8347 - val_loss: 0.3592 - val_accuracy: 0.8300\n",
            "Epoch 332/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8373 - val_loss: 0.3611 - val_accuracy: 0.8320\n",
            "Epoch 333/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8333 - val_loss: 0.3615 - val_accuracy: 0.8340\n",
            "Epoch 334/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8320 - val_loss: 0.3601 - val_accuracy: 0.8260\n",
            "Epoch 335/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8367 - val_loss: 0.3577 - val_accuracy: 0.8340\n",
            "Epoch 336/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8353 - val_loss: 0.3568 - val_accuracy: 0.8280\n",
            "Epoch 337/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8360 - val_loss: 0.3576 - val_accuracy: 0.8380\n",
            "Epoch 338/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8367 - val_loss: 0.3583 - val_accuracy: 0.8320\n",
            "Epoch 339/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8427 - val_loss: 0.3565 - val_accuracy: 0.8320\n",
            "Epoch 340/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8380 - val_loss: 0.3592 - val_accuracy: 0.8300\n",
            "Epoch 341/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8320 - val_loss: 0.3662 - val_accuracy: 0.8280\n",
            "Epoch 342/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8320 - val_loss: 0.3575 - val_accuracy: 0.8320\n",
            "Epoch 343/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8440 - val_loss: 0.3584 - val_accuracy: 0.8300\n",
            "Epoch 344/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8393 - val_loss: 0.3610 - val_accuracy: 0.8320\n",
            "Epoch 345/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8353 - val_loss: 0.3584 - val_accuracy: 0.8320\n",
            "Epoch 346/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8367 - val_loss: 0.3584 - val_accuracy: 0.8360\n",
            "Epoch 347/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8340 - val_loss: 0.3577 - val_accuracy: 0.8260\n",
            "Epoch 348/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8393 - val_loss: 0.3593 - val_accuracy: 0.8360\n",
            "Epoch 349/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8367 - val_loss: 0.3591 - val_accuracy: 0.8380\n",
            "Epoch 350/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8320 - val_loss: 0.3597 - val_accuracy: 0.8340\n",
            "Epoch 351/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8360 - val_loss: 0.3607 - val_accuracy: 0.8360\n",
            "Epoch 352/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8433 - val_loss: 0.3594 - val_accuracy: 0.8380\n",
            "Epoch 353/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8340 - val_loss: 0.3579 - val_accuracy: 0.8380\n",
            "Epoch 354/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8427 - val_loss: 0.3603 - val_accuracy: 0.8380\n",
            "Epoch 355/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8347 - val_loss: 0.3595 - val_accuracy: 0.8320\n",
            "Epoch 356/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8367 - val_loss: 0.3592 - val_accuracy: 0.8300\n",
            "Epoch 357/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8293 - val_loss: 0.3600 - val_accuracy: 0.8340\n",
            "Epoch 358/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8380 - val_loss: 0.3578 - val_accuracy: 0.8340\n",
            "Epoch 359/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8340 - val_loss: 0.3603 - val_accuracy: 0.8340\n",
            "Epoch 360/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8307 - val_loss: 0.3582 - val_accuracy: 0.8280\n",
            "Epoch 361/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8353 - val_loss: 0.3610 - val_accuracy: 0.8360\n",
            "Epoch 362/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8307 - val_loss: 0.3596 - val_accuracy: 0.8300\n",
            "Epoch 363/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8373 - val_loss: 0.3598 - val_accuracy: 0.8360\n",
            "Epoch 364/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8400 - val_loss: 0.3579 - val_accuracy: 0.8320\n",
            "Epoch 365/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8300 - val_loss: 0.3601 - val_accuracy: 0.8360\n",
            "Epoch 366/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8433 - val_loss: 0.3594 - val_accuracy: 0.8340\n",
            "Epoch 367/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8353 - val_loss: 0.3578 - val_accuracy: 0.8380\n",
            "Epoch 368/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8400 - val_loss: 0.3591 - val_accuracy: 0.8320\n",
            "Epoch 369/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8333 - val_loss: 0.3601 - val_accuracy: 0.8360\n",
            "Epoch 370/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8393 - val_loss: 0.3583 - val_accuracy: 0.8320\n",
            "Epoch 371/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8353 - val_loss: 0.3591 - val_accuracy: 0.8300\n",
            "Epoch 372/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8367 - val_loss: 0.3602 - val_accuracy: 0.8360\n",
            "Epoch 373/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8420 - val_loss: 0.3615 - val_accuracy: 0.8360\n",
            "Epoch 374/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8387 - val_loss: 0.3594 - val_accuracy: 0.8300\n",
            "Epoch 375/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8380 - val_loss: 0.3620 - val_accuracy: 0.8320\n",
            "Epoch 376/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8387 - val_loss: 0.3586 - val_accuracy: 0.8340\n",
            "Epoch 377/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8447 - val_loss: 0.3610 - val_accuracy: 0.8320\n",
            "Epoch 378/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8400 - val_loss: 0.3593 - val_accuracy: 0.8340\n",
            "Epoch 379/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8367 - val_loss: 0.3591 - val_accuracy: 0.8340\n",
            "Epoch 380/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8387 - val_loss: 0.3589 - val_accuracy: 0.8340\n",
            "Epoch 381/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8293 - val_loss: 0.3624 - val_accuracy: 0.8300\n",
            "Epoch 382/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8367 - val_loss: 0.3618 - val_accuracy: 0.8300\n",
            "Epoch 383/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8340 - val_loss: 0.3615 - val_accuracy: 0.8340\n",
            "Epoch 384/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8353 - val_loss: 0.3612 - val_accuracy: 0.8340\n",
            "Epoch 385/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8340 - val_loss: 0.3621 - val_accuracy: 0.8260\n",
            "Epoch 386/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8413 - val_loss: 0.3574 - val_accuracy: 0.8340\n",
            "Epoch 387/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8353 - val_loss: 0.3593 - val_accuracy: 0.8360\n",
            "Epoch 388/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8360 - val_loss: 0.3597 - val_accuracy: 0.8380\n",
            "Epoch 389/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8353 - val_loss: 0.3591 - val_accuracy: 0.8300\n",
            "Epoch 390/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8413 - val_loss: 0.3590 - val_accuracy: 0.8320\n",
            "Epoch 391/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8407 - val_loss: 0.3626 - val_accuracy: 0.8280\n",
            "Epoch 392/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8353 - val_loss: 0.3574 - val_accuracy: 0.8320\n",
            "Epoch 393/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8347 - val_loss: 0.3604 - val_accuracy: 0.8300\n",
            "Epoch 394/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8400 - val_loss: 0.3592 - val_accuracy: 0.8360\n",
            "Epoch 395/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8360 - val_loss: 0.3609 - val_accuracy: 0.8280\n",
            "Epoch 396/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8420 - val_loss: 0.3599 - val_accuracy: 0.8280\n",
            "Epoch 397/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8340 - val_loss: 0.3586 - val_accuracy: 0.8400\n",
            "Epoch 398/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8400 - val_loss: 0.3616 - val_accuracy: 0.8360\n",
            "Epoch 399/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8400 - val_loss: 0.3605 - val_accuracy: 0.8300\n",
            "Epoch 400/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8360 - val_loss: 0.3610 - val_accuracy: 0.8340\n",
            "Epoch 401/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8447 - val_loss: 0.3584 - val_accuracy: 0.8340\n",
            "Epoch 402/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8447 - val_loss: 0.3598 - val_accuracy: 0.8360\n",
            "Epoch 403/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8387 - val_loss: 0.3607 - val_accuracy: 0.8340\n",
            "Epoch 404/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8380 - val_loss: 0.3607 - val_accuracy: 0.8300\n",
            "Epoch 405/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8427 - val_loss: 0.3613 - val_accuracy: 0.8340\n",
            "Epoch 406/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8380 - val_loss: 0.3591 - val_accuracy: 0.8400\n",
            "Epoch 407/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8393 - val_loss: 0.3607 - val_accuracy: 0.8380\n",
            "Epoch 408/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8367 - val_loss: 0.3587 - val_accuracy: 0.8340\n",
            "Epoch 409/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8467 - val_loss: 0.3604 - val_accuracy: 0.8300\n",
            "Epoch 410/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8327 - val_loss: 0.3586 - val_accuracy: 0.8360\n",
            "Epoch 411/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8373 - val_loss: 0.3583 - val_accuracy: 0.8320\n",
            "Epoch 412/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8353 - val_loss: 0.3594 - val_accuracy: 0.8340\n",
            "Epoch 413/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8367 - val_loss: 0.3586 - val_accuracy: 0.8360\n",
            "Epoch 414/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8353 - val_loss: 0.3604 - val_accuracy: 0.8280\n",
            "Epoch 415/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8393 - val_loss: 0.3597 - val_accuracy: 0.8340\n",
            "Epoch 416/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8433 - val_loss: 0.3579 - val_accuracy: 0.8380\n",
            "Epoch 417/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8380 - val_loss: 0.3601 - val_accuracy: 0.8280\n",
            "Epoch 418/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8380 - val_loss: 0.3578 - val_accuracy: 0.8340\n",
            "Epoch 419/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8393 - val_loss: 0.3585 - val_accuracy: 0.8360\n",
            "Epoch 420/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8367 - val_loss: 0.3607 - val_accuracy: 0.8380\n",
            "Epoch 421/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8427 - val_loss: 0.3583 - val_accuracy: 0.8300\n",
            "Epoch 422/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8367 - val_loss: 0.3618 - val_accuracy: 0.8340\n",
            "Epoch 423/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8367 - val_loss: 0.3608 - val_accuracy: 0.8320\n",
            "Epoch 424/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8393 - val_loss: 0.3612 - val_accuracy: 0.8320\n",
            "Epoch 425/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8373 - val_loss: 0.3590 - val_accuracy: 0.8360\n",
            "Epoch 426/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.8380 - val_loss: 0.3604 - val_accuracy: 0.8280\n",
            "Epoch 427/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.8413 - val_loss: 0.3603 - val_accuracy: 0.8340\n",
            "Epoch 428/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8373 - val_loss: 0.3617 - val_accuracy: 0.8260\n",
            "Epoch 429/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8367 - val_loss: 0.3599 - val_accuracy: 0.8280\n",
            "Epoch 430/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8380 - val_loss: 0.3593 - val_accuracy: 0.8280\n",
            "Epoch 431/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8327 - val_loss: 0.3622 - val_accuracy: 0.8360\n",
            "Epoch 432/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8387 - val_loss: 0.3611 - val_accuracy: 0.8360\n",
            "Epoch 433/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8433 - val_loss: 0.3641 - val_accuracy: 0.8300\n",
            "Epoch 434/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8327 - val_loss: 0.3582 - val_accuracy: 0.8300\n",
            "Epoch 435/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8353 - val_loss: 0.3628 - val_accuracy: 0.8300\n",
            "Epoch 436/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8367 - val_loss: 0.3601 - val_accuracy: 0.8400\n",
            "Epoch 437/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8387 - val_loss: 0.3586 - val_accuracy: 0.8340\n",
            "Epoch 438/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8413 - val_loss: 0.3616 - val_accuracy: 0.8320\n",
            "Epoch 439/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8433 - val_loss: 0.3623 - val_accuracy: 0.8300\n",
            "Epoch 440/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8353 - val_loss: 0.3621 - val_accuracy: 0.8340\n",
            "Epoch 441/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.8427 - val_loss: 0.3601 - val_accuracy: 0.8340\n",
            "Epoch 442/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8360 - val_loss: 0.3584 - val_accuracy: 0.8320\n",
            "Epoch 443/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8373 - val_loss: 0.3591 - val_accuracy: 0.8320\n",
            "Epoch 444/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8347 - val_loss: 0.3596 - val_accuracy: 0.8300\n",
            "Epoch 445/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8453 - val_loss: 0.3579 - val_accuracy: 0.8300\n",
            "Epoch 446/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8393 - val_loss: 0.3607 - val_accuracy: 0.8280\n",
            "Epoch 447/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8367 - val_loss: 0.3591 - val_accuracy: 0.8340\n",
            "Epoch 448/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8413 - val_loss: 0.3608 - val_accuracy: 0.8360\n",
            "Epoch 449/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8340 - val_loss: 0.3590 - val_accuracy: 0.8300\n",
            "Epoch 450/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8380 - val_loss: 0.3609 - val_accuracy: 0.8340\n",
            "Epoch 451/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8387 - val_loss: 0.3621 - val_accuracy: 0.8300\n",
            "Epoch 452/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8313 - val_loss: 0.3625 - val_accuracy: 0.8300\n",
            "Epoch 453/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8447 - val_loss: 0.3605 - val_accuracy: 0.8280\n",
            "Epoch 454/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8347 - val_loss: 0.3630 - val_accuracy: 0.8280\n",
            "Epoch 455/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8407 - val_loss: 0.3606 - val_accuracy: 0.8300\n",
            "Epoch 456/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8373 - val_loss: 0.3625 - val_accuracy: 0.8360\n",
            "Epoch 457/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.8393 - val_loss: 0.3615 - val_accuracy: 0.8340\n",
            "Epoch 458/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8393 - val_loss: 0.3623 - val_accuracy: 0.8280\n",
            "Epoch 459/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8347 - val_loss: 0.3597 - val_accuracy: 0.8300\n",
            "Epoch 460/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8387 - val_loss: 0.3611 - val_accuracy: 0.8300\n",
            "Epoch 461/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8400 - val_loss: 0.3600 - val_accuracy: 0.8280\n",
            "Epoch 462/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8393 - val_loss: 0.3633 - val_accuracy: 0.8360\n",
            "Epoch 463/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8387 - val_loss: 0.3614 - val_accuracy: 0.8360\n",
            "Epoch 464/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8340 - val_loss: 0.3591 - val_accuracy: 0.8300\n",
            "Epoch 465/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8420 - val_loss: 0.3621 - val_accuracy: 0.8340\n",
            "Epoch 466/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8320 - val_loss: 0.3612 - val_accuracy: 0.8360\n",
            "Epoch 467/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8380 - val_loss: 0.3624 - val_accuracy: 0.8280\n",
            "Epoch 468/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8347 - val_loss: 0.3616 - val_accuracy: 0.8300\n",
            "Epoch 469/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8400 - val_loss: 0.3620 - val_accuracy: 0.8320\n",
            "Epoch 470/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8420 - val_loss: 0.3630 - val_accuracy: 0.8280\n",
            "Epoch 471/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8367 - val_loss: 0.3625 - val_accuracy: 0.8280\n",
            "Epoch 472/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8413 - val_loss: 0.3624 - val_accuracy: 0.8300\n",
            "Epoch 473/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8387 - val_loss: 0.3601 - val_accuracy: 0.8320\n",
            "Epoch 474/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8393 - val_loss: 0.3604 - val_accuracy: 0.8280\n",
            "Epoch 475/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8373 - val_loss: 0.3661 - val_accuracy: 0.8380\n",
            "Epoch 476/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8380 - val_loss: 0.3637 - val_accuracy: 0.8340\n",
            "Epoch 477/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8360 - val_loss: 0.3606 - val_accuracy: 0.8380\n",
            "Epoch 478/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8347 - val_loss: 0.3620 - val_accuracy: 0.8300\n",
            "Epoch 479/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8333 - val_loss: 0.3605 - val_accuracy: 0.8360\n",
            "Epoch 480/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8393 - val_loss: 0.3658 - val_accuracy: 0.8340\n",
            "Epoch 481/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8347 - val_loss: 0.3594 - val_accuracy: 0.8320\n",
            "Epoch 482/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.8373 - val_loss: 0.3626 - val_accuracy: 0.8380\n",
            "Epoch 483/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8387 - val_loss: 0.3623 - val_accuracy: 0.8280\n",
            "Epoch 484/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8367 - val_loss: 0.3605 - val_accuracy: 0.8300\n",
            "Epoch 485/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8340 - val_loss: 0.3602 - val_accuracy: 0.8280\n",
            "Epoch 486/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8373 - val_loss: 0.3589 - val_accuracy: 0.8280\n",
            "Epoch 487/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8287 - val_loss: 0.3631 - val_accuracy: 0.8260\n",
            "Epoch 488/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8353 - val_loss: 0.3622 - val_accuracy: 0.8260\n",
            "Epoch 489/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8427 - val_loss: 0.3615 - val_accuracy: 0.8320\n",
            "Epoch 490/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8427 - val_loss: 0.3616 - val_accuracy: 0.8380\n",
            "Epoch 491/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8393 - val_loss: 0.3597 - val_accuracy: 0.8380\n",
            "Epoch 492/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8327 - val_loss: 0.3619 - val_accuracy: 0.8300\n",
            "Epoch 493/1000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8387 - val_loss: 0.3608 - val_accuracy: 0.8260\n",
            "Epoch 494/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8340 - val_loss: 0.3624 - val_accuracy: 0.8300\n",
            "Epoch 495/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8320 - val_loss: 0.3631 - val_accuracy: 0.8280\n",
            "Epoch 496/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8380 - val_loss: 0.3620 - val_accuracy: 0.8340\n",
            "Epoch 497/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8360 - val_loss: 0.3619 - val_accuracy: 0.8380\n",
            "Epoch 498/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8393 - val_loss: 0.3643 - val_accuracy: 0.8260\n",
            "Epoch 499/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8427 - val_loss: 0.3639 - val_accuracy: 0.8320\n",
            "Epoch 500/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8373 - val_loss: 0.3580 - val_accuracy: 0.8240\n",
            "Epoch 501/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8340 - val_loss: 0.3652 - val_accuracy: 0.8240\n",
            "Epoch 502/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8367 - val_loss: 0.3624 - val_accuracy: 0.8360\n",
            "Epoch 503/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8407 - val_loss: 0.3589 - val_accuracy: 0.8260\n",
            "Epoch 504/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8347 - val_loss: 0.3620 - val_accuracy: 0.8300\n",
            "Epoch 505/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8387 - val_loss: 0.3612 - val_accuracy: 0.8280\n",
            "Epoch 506/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8400 - val_loss: 0.3600 - val_accuracy: 0.8400\n",
            "Epoch 507/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8313 - val_loss: 0.3630 - val_accuracy: 0.8320\n",
            "Epoch 508/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8373 - val_loss: 0.3605 - val_accuracy: 0.8300\n",
            "Epoch 509/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8393 - val_loss: 0.3624 - val_accuracy: 0.8340\n",
            "Epoch 510/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8427 - val_loss: 0.3611 - val_accuracy: 0.8300\n",
            "Epoch 511/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8360 - val_loss: 0.3618 - val_accuracy: 0.8380\n",
            "Epoch 512/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8367 - val_loss: 0.3615 - val_accuracy: 0.8320\n",
            "Epoch 513/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8300 - val_loss: 0.3589 - val_accuracy: 0.8260\n",
            "Epoch 514/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.8367 - val_loss: 0.3616 - val_accuracy: 0.8380\n",
            "Epoch 515/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8313 - val_loss: 0.3603 - val_accuracy: 0.8240\n",
            "Epoch 516/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8367 - val_loss: 0.3607 - val_accuracy: 0.8320\n",
            "Epoch 517/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8300 - val_loss: 0.3594 - val_accuracy: 0.8240\n",
            "Epoch 518/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8347 - val_loss: 0.3595 - val_accuracy: 0.8360\n",
            "Epoch 519/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8380 - val_loss: 0.3632 - val_accuracy: 0.8340\n",
            "Epoch 520/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8387 - val_loss: 0.3598 - val_accuracy: 0.8380\n",
            "Epoch 521/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8327 - val_loss: 0.3589 - val_accuracy: 0.8360\n",
            "Epoch 522/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8353 - val_loss: 0.3605 - val_accuracy: 0.8320\n",
            "Epoch 523/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8413 - val_loss: 0.3617 - val_accuracy: 0.8220\n",
            "Epoch 524/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8360 - val_loss: 0.3614 - val_accuracy: 0.8320\n",
            "Epoch 525/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8387 - val_loss: 0.3630 - val_accuracy: 0.8300\n",
            "Epoch 526/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8307 - val_loss: 0.3620 - val_accuracy: 0.8280\n",
            "Epoch 527/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8407 - val_loss: 0.3624 - val_accuracy: 0.8300\n",
            "Epoch 528/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8320 - val_loss: 0.3601 - val_accuracy: 0.8260\n",
            "Epoch 529/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8327 - val_loss: 0.3630 - val_accuracy: 0.8320\n",
            "Epoch 530/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8367 - val_loss: 0.3586 - val_accuracy: 0.8260\n",
            "Epoch 531/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8373 - val_loss: 0.3606 - val_accuracy: 0.8300\n",
            "Epoch 532/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8313 - val_loss: 0.3626 - val_accuracy: 0.8280\n",
            "Epoch 533/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8313 - val_loss: 0.3633 - val_accuracy: 0.8300\n",
            "Epoch 534/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8340 - val_loss: 0.3591 - val_accuracy: 0.8260\n",
            "Epoch 535/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8367 - val_loss: 0.3587 - val_accuracy: 0.8300\n",
            "Epoch 536/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8353 - val_loss: 0.3604 - val_accuracy: 0.8240\n",
            "Epoch 537/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8400 - val_loss: 0.3610 - val_accuracy: 0.8300\n",
            "Epoch 538/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8373 - val_loss: 0.3594 - val_accuracy: 0.8320\n",
            "Epoch 539/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8340 - val_loss: 0.3601 - val_accuracy: 0.8320\n",
            "Epoch 540/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8327 - val_loss: 0.3606 - val_accuracy: 0.8300\n",
            "Epoch 541/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8327 - val_loss: 0.3627 - val_accuracy: 0.8340\n",
            "Epoch 542/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8360 - val_loss: 0.3616 - val_accuracy: 0.8320\n",
            "Epoch 543/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8393 - val_loss: 0.3610 - val_accuracy: 0.8320\n",
            "Epoch 544/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8427 - val_loss: 0.3614 - val_accuracy: 0.8300\n",
            "Epoch 545/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8427 - val_loss: 0.3617 - val_accuracy: 0.8260\n",
            "Epoch 546/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8340 - val_loss: 0.3639 - val_accuracy: 0.8300\n",
            "Epoch 547/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8440 - val_loss: 0.3636 - val_accuracy: 0.8340\n",
            "Epoch 548/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8413 - val_loss: 0.3624 - val_accuracy: 0.8380\n",
            "Epoch 549/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8380 - val_loss: 0.3675 - val_accuracy: 0.8360\n",
            "Epoch 550/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8420 - val_loss: 0.3633 - val_accuracy: 0.8340\n",
            "Epoch 551/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8367 - val_loss: 0.3669 - val_accuracy: 0.8340\n",
            "Epoch 552/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8380 - val_loss: 0.3620 - val_accuracy: 0.8300\n",
            "Epoch 553/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8347 - val_loss: 0.3634 - val_accuracy: 0.8400\n",
            "Epoch 554/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8373 - val_loss: 0.3631 - val_accuracy: 0.8320\n",
            "Epoch 555/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8400 - val_loss: 0.3630 - val_accuracy: 0.8280\n",
            "Epoch 556/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8393 - val_loss: 0.3655 - val_accuracy: 0.8380\n",
            "Epoch 557/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8440 - val_loss: 0.3605 - val_accuracy: 0.8340\n",
            "Epoch 558/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8387 - val_loss: 0.3646 - val_accuracy: 0.8280\n",
            "Epoch 559/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8447 - val_loss: 0.3639 - val_accuracy: 0.8320\n",
            "Epoch 560/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8407 - val_loss: 0.3642 - val_accuracy: 0.8320\n",
            "Epoch 561/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8447 - val_loss: 0.3619 - val_accuracy: 0.8320\n",
            "Epoch 562/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8420 - val_loss: 0.3622 - val_accuracy: 0.8400\n",
            "Epoch 563/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8367 - val_loss: 0.3627 - val_accuracy: 0.8300\n",
            "Epoch 564/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8467 - val_loss: 0.3648 - val_accuracy: 0.8440\n",
            "Epoch 565/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8387 - val_loss: 0.3621 - val_accuracy: 0.8320\n",
            "Epoch 566/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8433 - val_loss: 0.3631 - val_accuracy: 0.8360\n",
            "Epoch 567/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8360 - val_loss: 0.3616 - val_accuracy: 0.8340\n",
            "Epoch 568/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8400 - val_loss: 0.3605 - val_accuracy: 0.8340\n",
            "Epoch 569/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8420 - val_loss: 0.3631 - val_accuracy: 0.8340\n",
            "Epoch 570/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8420 - val_loss: 0.3618 - val_accuracy: 0.8380\n",
            "Epoch 571/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8373 - val_loss: 0.3623 - val_accuracy: 0.8340\n",
            "Epoch 572/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8467 - val_loss: 0.3640 - val_accuracy: 0.8360\n",
            "Epoch 573/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8400 - val_loss: 0.3613 - val_accuracy: 0.8340\n",
            "Epoch 574/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8447 - val_loss: 0.3636 - val_accuracy: 0.8360\n",
            "Epoch 575/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8440 - val_loss: 0.3625 - val_accuracy: 0.8340\n",
            "Epoch 576/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8407 - val_loss: 0.3620 - val_accuracy: 0.8340\n",
            "Epoch 577/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8407 - val_loss: 0.3624 - val_accuracy: 0.8360\n",
            "Epoch 578/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8440 - val_loss: 0.3643 - val_accuracy: 0.8400\n",
            "Epoch 579/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8433 - val_loss: 0.3655 - val_accuracy: 0.8320\n",
            "Epoch 580/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8347 - val_loss: 0.3623 - val_accuracy: 0.8320\n",
            "Epoch 581/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8400 - val_loss: 0.3641 - val_accuracy: 0.8460\n",
            "Epoch 582/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8433 - val_loss: 0.3650 - val_accuracy: 0.8280\n",
            "Epoch 583/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8473 - val_loss: 0.3697 - val_accuracy: 0.8280\n",
            "Epoch 584/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8380 - val_loss: 0.3622 - val_accuracy: 0.8400\n",
            "Epoch 585/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8400 - val_loss: 0.3653 - val_accuracy: 0.8360\n",
            "Epoch 586/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8393 - val_loss: 0.3636 - val_accuracy: 0.8380\n",
            "Epoch 587/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8360 - val_loss: 0.3657 - val_accuracy: 0.8320\n",
            "Epoch 588/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8433 - val_loss: 0.3641 - val_accuracy: 0.8360\n",
            "Epoch 589/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8413 - val_loss: 0.3629 - val_accuracy: 0.8380\n",
            "Epoch 590/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8440 - val_loss: 0.3611 - val_accuracy: 0.8340\n",
            "Epoch 591/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8420 - val_loss: 0.3626 - val_accuracy: 0.8380\n",
            "Epoch 592/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8500 - val_loss: 0.3625 - val_accuracy: 0.8380\n",
            "Epoch 593/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8460 - val_loss: 0.3617 - val_accuracy: 0.8320\n",
            "Epoch 594/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8467 - val_loss: 0.3628 - val_accuracy: 0.8320\n",
            "Epoch 595/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8413 - val_loss: 0.3611 - val_accuracy: 0.8340\n",
            "Epoch 596/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8420 - val_loss: 0.3625 - val_accuracy: 0.8320\n",
            "Epoch 597/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8400 - val_loss: 0.3624 - val_accuracy: 0.8340\n",
            "Epoch 598/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8460 - val_loss: 0.3643 - val_accuracy: 0.8380\n",
            "Epoch 599/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8447 - val_loss: 0.3656 - val_accuracy: 0.8380\n",
            "Epoch 600/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8400 - val_loss: 0.3631 - val_accuracy: 0.8420\n",
            "Epoch 601/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8453 - val_loss: 0.3613 - val_accuracy: 0.8380\n",
            "Epoch 602/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8387 - val_loss: 0.3652 - val_accuracy: 0.8300\n",
            "Epoch 603/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8453 - val_loss: 0.3649 - val_accuracy: 0.8300\n",
            "Epoch 604/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8360 - val_loss: 0.3621 - val_accuracy: 0.8360\n",
            "Epoch 605/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8400 - val_loss: 0.3640 - val_accuracy: 0.8320\n",
            "Epoch 606/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8407 - val_loss: 0.3630 - val_accuracy: 0.8320\n",
            "Epoch 607/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8420 - val_loss: 0.3638 - val_accuracy: 0.8340\n",
            "Epoch 608/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8407 - val_loss: 0.3606 - val_accuracy: 0.8340\n",
            "Epoch 609/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8420 - val_loss: 0.3665 - val_accuracy: 0.8340\n",
            "Epoch 610/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8367 - val_loss: 0.3651 - val_accuracy: 0.8240\n",
            "Epoch 611/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8427 - val_loss: 0.3656 - val_accuracy: 0.8320\n",
            "Epoch 612/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8473 - val_loss: 0.3632 - val_accuracy: 0.8340\n",
            "Epoch 613/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8473 - val_loss: 0.3621 - val_accuracy: 0.8340\n",
            "Epoch 614/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8387 - val_loss: 0.3640 - val_accuracy: 0.8400\n",
            "Epoch 615/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8420 - val_loss: 0.3640 - val_accuracy: 0.8400\n",
            "Epoch 616/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8400 - val_loss: 0.3627 - val_accuracy: 0.8320\n",
            "Epoch 617/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8427 - val_loss: 0.3626 - val_accuracy: 0.8300\n",
            "Epoch 618/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8360 - val_loss: 0.3630 - val_accuracy: 0.8380\n",
            "Epoch 619/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8487 - val_loss: 0.3664 - val_accuracy: 0.8280\n",
            "Epoch 620/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8420 - val_loss: 0.3652 - val_accuracy: 0.8340\n",
            "Epoch 621/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8400 - val_loss: 0.3624 - val_accuracy: 0.8320\n",
            "Epoch 622/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8453 - val_loss: 0.3613 - val_accuracy: 0.8340\n",
            "Epoch 623/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8453 - val_loss: 0.3630 - val_accuracy: 0.8320\n",
            "Epoch 624/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8433 - val_loss: 0.3624 - val_accuracy: 0.8380\n",
            "Epoch 625/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8407 - val_loss: 0.3614 - val_accuracy: 0.8320\n",
            "Epoch 626/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8473 - val_loss: 0.3629 - val_accuracy: 0.8380\n",
            "Epoch 627/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8387 - val_loss: 0.3631 - val_accuracy: 0.8380\n",
            "Epoch 628/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8447 - val_loss: 0.3668 - val_accuracy: 0.8320\n",
            "Epoch 629/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8433 - val_loss: 0.3647 - val_accuracy: 0.8360\n",
            "Epoch 630/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8447 - val_loss: 0.3618 - val_accuracy: 0.8340\n",
            "Epoch 631/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8347 - val_loss: 0.3633 - val_accuracy: 0.8320\n",
            "Epoch 632/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8413 - val_loss: 0.3652 - val_accuracy: 0.8320\n",
            "Epoch 633/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8447 - val_loss: 0.3650 - val_accuracy: 0.8320\n",
            "Epoch 634/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8367 - val_loss: 0.3631 - val_accuracy: 0.8340\n",
            "Epoch 635/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8500 - val_loss: 0.3633 - val_accuracy: 0.8340\n",
            "Epoch 636/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8440 - val_loss: 0.3656 - val_accuracy: 0.8380\n",
            "Epoch 637/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8447 - val_loss: 0.3631 - val_accuracy: 0.8320\n",
            "Epoch 638/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8407 - val_loss: 0.3620 - val_accuracy: 0.8360\n",
            "Epoch 639/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8427 - val_loss: 0.3650 - val_accuracy: 0.8320\n",
            "Epoch 640/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8420 - val_loss: 0.3644 - val_accuracy: 0.8420\n",
            "Epoch 641/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8367 - val_loss: 0.3621 - val_accuracy: 0.8340\n",
            "Epoch 642/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8387 - val_loss: 0.3621 - val_accuracy: 0.8340\n",
            "Epoch 643/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8447 - val_loss: 0.3642 - val_accuracy: 0.8400\n",
            "Epoch 644/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8413 - val_loss: 0.3628 - val_accuracy: 0.8320\n",
            "Epoch 645/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8460 - val_loss: 0.3633 - val_accuracy: 0.8300\n",
            "Epoch 646/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8440 - val_loss: 0.3638 - val_accuracy: 0.8360\n",
            "Epoch 647/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8480 - val_loss: 0.3639 - val_accuracy: 0.8340\n",
            "Epoch 648/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8407 - val_loss: 0.3651 - val_accuracy: 0.8260\n",
            "Epoch 649/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8420 - val_loss: 0.3655 - val_accuracy: 0.8360\n",
            "Epoch 650/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8427 - val_loss: 0.3631 - val_accuracy: 0.8320\n",
            "Epoch 651/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8393 - val_loss: 0.3614 - val_accuracy: 0.8320\n",
            "Epoch 652/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8400 - val_loss: 0.3665 - val_accuracy: 0.8400\n",
            "Epoch 653/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8340 - val_loss: 0.3707 - val_accuracy: 0.8240\n",
            "Epoch 654/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8413 - val_loss: 0.3639 - val_accuracy: 0.8420\n",
            "Epoch 655/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8440 - val_loss: 0.3631 - val_accuracy: 0.8280\n",
            "Epoch 656/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8400 - val_loss: 0.3643 - val_accuracy: 0.8360\n",
            "Epoch 657/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8493 - val_loss: 0.3634 - val_accuracy: 0.8380\n",
            "Epoch 658/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8393 - val_loss: 0.3628 - val_accuracy: 0.8340\n",
            "Epoch 659/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8473 - val_loss: 0.3644 - val_accuracy: 0.8340\n",
            "Epoch 660/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8380 - val_loss: 0.3640 - val_accuracy: 0.8280\n",
            "Epoch 661/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8380 - val_loss: 0.3720 - val_accuracy: 0.8300\n",
            "Epoch 662/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8447 - val_loss: 0.3677 - val_accuracy: 0.8400\n",
            "Epoch 663/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8407 - val_loss: 0.3652 - val_accuracy: 0.8320\n",
            "Epoch 664/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8353 - val_loss: 0.3640 - val_accuracy: 0.8360\n",
            "Epoch 665/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8420 - val_loss: 0.3639 - val_accuracy: 0.8380\n",
            "Epoch 666/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8427 - val_loss: 0.3638 - val_accuracy: 0.8360\n",
            "Epoch 667/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8400 - val_loss: 0.3650 - val_accuracy: 0.8400\n",
            "Epoch 668/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8480 - val_loss: 0.3639 - val_accuracy: 0.8360\n",
            "Epoch 669/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8413 - val_loss: 0.3645 - val_accuracy: 0.8380\n",
            "Epoch 670/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8427 - val_loss: 0.3622 - val_accuracy: 0.8380\n",
            "Epoch 671/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8480 - val_loss: 0.3657 - val_accuracy: 0.8320\n",
            "Epoch 672/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8420 - val_loss: 0.3645 - val_accuracy: 0.8360\n",
            "Epoch 673/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8400 - val_loss: 0.3661 - val_accuracy: 0.8260\n",
            "Epoch 674/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8507 - val_loss: 0.3643 - val_accuracy: 0.8340\n",
            "Epoch 675/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8393 - val_loss: 0.3629 - val_accuracy: 0.8380\n",
            "Epoch 676/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8453 - val_loss: 0.3664 - val_accuracy: 0.8400\n",
            "Epoch 677/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8420 - val_loss: 0.3646 - val_accuracy: 0.8380\n",
            "Epoch 678/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8447 - val_loss: 0.3663 - val_accuracy: 0.8400\n",
            "Epoch 679/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8380 - val_loss: 0.3636 - val_accuracy: 0.8340\n",
            "Epoch 680/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8440 - val_loss: 0.3623 - val_accuracy: 0.8340\n",
            "Epoch 681/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8420 - val_loss: 0.3662 - val_accuracy: 0.8320\n",
            "Epoch 682/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8467 - val_loss: 0.3683 - val_accuracy: 0.8320\n",
            "Epoch 683/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8393 - val_loss: 0.3663 - val_accuracy: 0.8380\n",
            "Epoch 684/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8393 - val_loss: 0.3624 - val_accuracy: 0.8300\n",
            "Epoch 685/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8447 - val_loss: 0.3642 - val_accuracy: 0.8320\n",
            "Epoch 686/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8427 - val_loss: 0.3640 - val_accuracy: 0.8360\n",
            "Epoch 687/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8487 - val_loss: 0.3644 - val_accuracy: 0.8360\n",
            "Epoch 688/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8440 - val_loss: 0.3634 - val_accuracy: 0.8320\n",
            "Epoch 689/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8453 - val_loss: 0.3657 - val_accuracy: 0.8360\n",
            "Epoch 690/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8440 - val_loss: 0.3647 - val_accuracy: 0.8320\n",
            "Epoch 691/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8413 - val_loss: 0.3642 - val_accuracy: 0.8360\n",
            "Epoch 692/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8427 - val_loss: 0.3644 - val_accuracy: 0.8340\n",
            "Epoch 693/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8480 - val_loss: 0.3647 - val_accuracy: 0.8340\n",
            "Epoch 694/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8387 - val_loss: 0.3652 - val_accuracy: 0.8420\n",
            "Epoch 695/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8493 - val_loss: 0.3634 - val_accuracy: 0.8300\n",
            "Epoch 696/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8367 - val_loss: 0.3645 - val_accuracy: 0.8360\n",
            "Epoch 697/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8380 - val_loss: 0.3655 - val_accuracy: 0.8400\n",
            "Epoch 698/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8447 - val_loss: 0.3676 - val_accuracy: 0.8360\n",
            "Epoch 699/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8420 - val_loss: 0.3649 - val_accuracy: 0.8320\n",
            "Epoch 700/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8480 - val_loss: 0.3643 - val_accuracy: 0.8400\n",
            "Epoch 701/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8420 - val_loss: 0.3656 - val_accuracy: 0.8400\n",
            "Epoch 702/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8400 - val_loss: 0.3675 - val_accuracy: 0.8360\n",
            "Epoch 703/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8413 - val_loss: 0.3646 - val_accuracy: 0.8340\n",
            "Epoch 704/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8467 - val_loss: 0.3657 - val_accuracy: 0.8440\n",
            "Epoch 705/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8420 - val_loss: 0.3625 - val_accuracy: 0.8360\n",
            "Epoch 706/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8473 - val_loss: 0.3648 - val_accuracy: 0.8360\n",
            "Epoch 707/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8433 - val_loss: 0.3648 - val_accuracy: 0.8300\n",
            "Epoch 708/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8393 - val_loss: 0.3696 - val_accuracy: 0.8320\n",
            "Epoch 709/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8413 - val_loss: 0.3674 - val_accuracy: 0.8400\n",
            "Epoch 710/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8413 - val_loss: 0.3635 - val_accuracy: 0.8460\n",
            "Epoch 711/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8427 - val_loss: 0.3640 - val_accuracy: 0.8340\n",
            "Epoch 712/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8440 - val_loss: 0.3662 - val_accuracy: 0.8400\n",
            "Epoch 713/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8440 - val_loss: 0.3644 - val_accuracy: 0.8320\n",
            "Epoch 714/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8480 - val_loss: 0.3645 - val_accuracy: 0.8320\n",
            "Epoch 715/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8467 - val_loss: 0.3668 - val_accuracy: 0.8380\n",
            "Epoch 716/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8413 - val_loss: 0.3659 - val_accuracy: 0.8340\n",
            "Epoch 717/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8393 - val_loss: 0.3659 - val_accuracy: 0.8340\n",
            "Epoch 718/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8453 - val_loss: 0.3637 - val_accuracy: 0.8380\n",
            "Epoch 719/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8400 - val_loss: 0.3652 - val_accuracy: 0.8420\n",
            "Epoch 720/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8393 - val_loss: 0.3690 - val_accuracy: 0.8300\n",
            "Epoch 721/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8480 - val_loss: 0.3642 - val_accuracy: 0.8360\n",
            "Epoch 722/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8413 - val_loss: 0.3654 - val_accuracy: 0.8380\n",
            "Epoch 723/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8447 - val_loss: 0.3655 - val_accuracy: 0.8360\n",
            "Epoch 724/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8427 - val_loss: 0.3649 - val_accuracy: 0.8320\n",
            "Epoch 725/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8420 - val_loss: 0.3640 - val_accuracy: 0.8440\n",
            "Epoch 726/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8473 - val_loss: 0.3671 - val_accuracy: 0.8340\n",
            "Epoch 727/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8453 - val_loss: 0.3649 - val_accuracy: 0.8380\n",
            "Epoch 728/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8387 - val_loss: 0.3645 - val_accuracy: 0.8340\n",
            "Epoch 729/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8380 - val_loss: 0.3686 - val_accuracy: 0.8340\n",
            "Epoch 730/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8493 - val_loss: 0.3632 - val_accuracy: 0.8320\n",
            "Epoch 731/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8393 - val_loss: 0.3656 - val_accuracy: 0.8340\n",
            "Epoch 732/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8400 - val_loss: 0.3662 - val_accuracy: 0.8280\n",
            "Epoch 733/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8427 - val_loss: 0.3663 - val_accuracy: 0.8360\n",
            "Epoch 734/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8387 - val_loss: 0.3670 - val_accuracy: 0.8500\n",
            "Epoch 735/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8433 - val_loss: 0.3647 - val_accuracy: 0.8320\n",
            "Epoch 736/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8440 - val_loss: 0.3645 - val_accuracy: 0.8420\n",
            "Epoch 737/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8407 - val_loss: 0.3646 - val_accuracy: 0.8300\n",
            "Epoch 738/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8473 - val_loss: 0.3653 - val_accuracy: 0.8360\n",
            "Epoch 739/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8480 - val_loss: 0.3642 - val_accuracy: 0.8280\n",
            "Epoch 740/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8427 - val_loss: 0.3653 - val_accuracy: 0.8320\n",
            "Epoch 741/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8433 - val_loss: 0.3654 - val_accuracy: 0.8320\n",
            "Epoch 742/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8413 - val_loss: 0.3651 - val_accuracy: 0.8360\n",
            "Epoch 743/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8413 - val_loss: 0.3665 - val_accuracy: 0.8380\n",
            "Epoch 744/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8473 - val_loss: 0.3651 - val_accuracy: 0.8400\n",
            "Epoch 745/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8440 - val_loss: 0.3661 - val_accuracy: 0.8420\n",
            "Epoch 746/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8447 - val_loss: 0.3654 - val_accuracy: 0.8320\n",
            "Epoch 747/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8467 - val_loss: 0.3674 - val_accuracy: 0.8280\n",
            "Epoch 748/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8400 - val_loss: 0.3663 - val_accuracy: 0.8340\n",
            "Epoch 749/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8400 - val_loss: 0.3647 - val_accuracy: 0.8360\n",
            "Epoch 750/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8487 - val_loss: 0.3647 - val_accuracy: 0.8400\n",
            "Epoch 751/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8487 - val_loss: 0.3670 - val_accuracy: 0.8420\n",
            "Epoch 752/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8400 - val_loss: 0.3669 - val_accuracy: 0.8420\n",
            "Epoch 753/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8407 - val_loss: 0.3699 - val_accuracy: 0.8280\n",
            "Epoch 754/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8360 - val_loss: 0.3645 - val_accuracy: 0.8340\n",
            "Epoch 755/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8453 - val_loss: 0.3652 - val_accuracy: 0.8340\n",
            "Epoch 756/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8373 - val_loss: 0.3677 - val_accuracy: 0.8360\n",
            "Epoch 757/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8407 - val_loss: 0.3648 - val_accuracy: 0.8400\n",
            "Epoch 758/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8453 - val_loss: 0.3650 - val_accuracy: 0.8380\n",
            "Epoch 759/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8413 - val_loss: 0.3663 - val_accuracy: 0.8440\n",
            "Epoch 760/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8453 - val_loss: 0.3697 - val_accuracy: 0.8440\n",
            "Epoch 761/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8447 - val_loss: 0.3701 - val_accuracy: 0.8260\n",
            "Epoch 762/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8413 - val_loss: 0.3630 - val_accuracy: 0.8460\n",
            "Epoch 763/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8360 - val_loss: 0.3682 - val_accuracy: 0.8280\n",
            "Epoch 764/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8427 - val_loss: 0.3647 - val_accuracy: 0.8400\n",
            "Epoch 765/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3468 - accuracy: 0.8460 - val_loss: 0.3649 - val_accuracy: 0.8360\n",
            "Epoch 766/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8400 - val_loss: 0.3644 - val_accuracy: 0.8340\n",
            "Epoch 767/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8440 - val_loss: 0.3643 - val_accuracy: 0.8380\n",
            "Epoch 768/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8433 - val_loss: 0.3665 - val_accuracy: 0.8340\n",
            "Epoch 769/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8440 - val_loss: 0.3676 - val_accuracy: 0.8380\n",
            "Epoch 770/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8460 - val_loss: 0.3661 - val_accuracy: 0.8400\n",
            "Epoch 771/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8407 - val_loss: 0.3677 - val_accuracy: 0.8320\n",
            "Epoch 772/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8387 - val_loss: 0.3671 - val_accuracy: 0.8380\n",
            "Epoch 773/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8460 - val_loss: 0.3652 - val_accuracy: 0.8380\n",
            "Epoch 774/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8387 - val_loss: 0.3658 - val_accuracy: 0.8340\n",
            "Epoch 775/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8453 - val_loss: 0.3667 - val_accuracy: 0.8380\n",
            "Epoch 776/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8507 - val_loss: 0.3660 - val_accuracy: 0.8360\n",
            "Epoch 777/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8407 - val_loss: 0.3633 - val_accuracy: 0.8320\n",
            "Epoch 778/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8460 - val_loss: 0.3649 - val_accuracy: 0.8320\n",
            "Epoch 779/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8407 - val_loss: 0.3677 - val_accuracy: 0.8280\n",
            "Epoch 780/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8440 - val_loss: 0.3671 - val_accuracy: 0.8340\n",
            "Epoch 781/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8407 - val_loss: 0.3663 - val_accuracy: 0.8320\n",
            "Epoch 782/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8447 - val_loss: 0.3671 - val_accuracy: 0.8340\n",
            "Epoch 783/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8407 - val_loss: 0.3683 - val_accuracy: 0.8360\n",
            "Epoch 784/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3474 - accuracy: 0.8460 - val_loss: 0.3654 - val_accuracy: 0.8380\n",
            "Epoch 785/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8420 - val_loss: 0.3651 - val_accuracy: 0.8380\n",
            "Epoch 786/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8440 - val_loss: 0.3663 - val_accuracy: 0.8340\n",
            "Epoch 787/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8440 - val_loss: 0.3660 - val_accuracy: 0.8340\n",
            "Epoch 788/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8473 - val_loss: 0.3674 - val_accuracy: 0.8320\n",
            "Epoch 789/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8427 - val_loss: 0.3669 - val_accuracy: 0.8440\n",
            "Epoch 790/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8467 - val_loss: 0.3668 - val_accuracy: 0.8420\n",
            "Epoch 791/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8467 - val_loss: 0.3639 - val_accuracy: 0.8380\n",
            "Epoch 792/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8453 - val_loss: 0.3653 - val_accuracy: 0.8400\n",
            "Epoch 793/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8453 - val_loss: 0.3662 - val_accuracy: 0.8420\n",
            "Epoch 794/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8460 - val_loss: 0.3656 - val_accuracy: 0.8380\n",
            "Epoch 795/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8453 - val_loss: 0.3643 - val_accuracy: 0.8300\n",
            "Epoch 796/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8367 - val_loss: 0.3661 - val_accuracy: 0.8340\n",
            "Epoch 797/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8393 - val_loss: 0.3654 - val_accuracy: 0.8400\n",
            "Epoch 798/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8440 - val_loss: 0.3652 - val_accuracy: 0.8340\n",
            "Epoch 799/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8393 - val_loss: 0.3639 - val_accuracy: 0.8340\n",
            "Epoch 800/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8433 - val_loss: 0.3671 - val_accuracy: 0.8360\n",
            "Epoch 801/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8460 - val_loss: 0.3664 - val_accuracy: 0.8320\n",
            "Epoch 802/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8380 - val_loss: 0.3660 - val_accuracy: 0.8360\n",
            "Epoch 803/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8400 - val_loss: 0.3655 - val_accuracy: 0.8320\n",
            "Epoch 804/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3474 - accuracy: 0.8427 - val_loss: 0.3656 - val_accuracy: 0.8420\n",
            "Epoch 805/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8427 - val_loss: 0.3646 - val_accuracy: 0.8380\n",
            "Epoch 806/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8433 - val_loss: 0.3678 - val_accuracy: 0.8400\n",
            "Epoch 807/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8393 - val_loss: 0.3647 - val_accuracy: 0.8360\n",
            "Epoch 808/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8440 - val_loss: 0.3662 - val_accuracy: 0.8300\n",
            "Epoch 809/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8493 - val_loss: 0.3660 - val_accuracy: 0.8360\n",
            "Epoch 810/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8413 - val_loss: 0.3668 - val_accuracy: 0.8340\n",
            "Epoch 811/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8420 - val_loss: 0.3669 - val_accuracy: 0.8420\n",
            "Epoch 812/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8433 - val_loss: 0.3687 - val_accuracy: 0.8320\n",
            "Epoch 813/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8393 - val_loss: 0.3670 - val_accuracy: 0.8320\n",
            "Epoch 814/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8487 - val_loss: 0.3669 - val_accuracy: 0.8320\n",
            "Epoch 815/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8387 - val_loss: 0.3643 - val_accuracy: 0.8420\n",
            "Epoch 816/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8407 - val_loss: 0.3678 - val_accuracy: 0.8320\n",
            "Epoch 817/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8380 - val_loss: 0.3645 - val_accuracy: 0.8340\n",
            "Epoch 818/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8473 - val_loss: 0.3670 - val_accuracy: 0.8320\n",
            "Epoch 819/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8513 - val_loss: 0.3669 - val_accuracy: 0.8380\n",
            "Epoch 820/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8393 - val_loss: 0.3679 - val_accuracy: 0.8320\n",
            "Epoch 821/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8420 - val_loss: 0.3681 - val_accuracy: 0.8380\n",
            "Epoch 822/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8447 - val_loss: 0.3650 - val_accuracy: 0.8360\n",
            "Epoch 823/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8427 - val_loss: 0.3657 - val_accuracy: 0.8340\n",
            "Epoch 824/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8427 - val_loss: 0.3663 - val_accuracy: 0.8380\n",
            "Epoch 825/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8440 - val_loss: 0.3701 - val_accuracy: 0.8320\n",
            "Epoch 826/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8440 - val_loss: 0.3647 - val_accuracy: 0.8320\n",
            "Epoch 827/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8427 - val_loss: 0.3666 - val_accuracy: 0.8360\n",
            "Epoch 828/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8373 - val_loss: 0.3666 - val_accuracy: 0.8260\n",
            "Epoch 829/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8440 - val_loss: 0.3665 - val_accuracy: 0.8400\n",
            "Epoch 830/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8413 - val_loss: 0.3686 - val_accuracy: 0.8340\n",
            "Epoch 831/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8440 - val_loss: 0.3637 - val_accuracy: 0.8400\n",
            "Epoch 832/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8453 - val_loss: 0.3716 - val_accuracy: 0.8320\n",
            "Epoch 833/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8453 - val_loss: 0.3673 - val_accuracy: 0.8320\n",
            "Epoch 834/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8367 - val_loss: 0.3642 - val_accuracy: 0.8360\n",
            "Epoch 835/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8427 - val_loss: 0.3673 - val_accuracy: 0.8300\n",
            "Epoch 836/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8433 - val_loss: 0.3654 - val_accuracy: 0.8320\n",
            "Epoch 837/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8453 - val_loss: 0.3686 - val_accuracy: 0.8260\n",
            "Epoch 838/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8487 - val_loss: 0.3679 - val_accuracy: 0.8340\n",
            "Epoch 839/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8407 - val_loss: 0.3660 - val_accuracy: 0.8340\n",
            "Epoch 840/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8407 - val_loss: 0.3649 - val_accuracy: 0.8380\n",
            "Epoch 841/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8380 - val_loss: 0.3655 - val_accuracy: 0.8340\n",
            "Epoch 842/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8427 - val_loss: 0.3682 - val_accuracy: 0.8300\n",
            "Epoch 843/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8380 - val_loss: 0.3668 - val_accuracy: 0.8360\n",
            "Epoch 844/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8453 - val_loss: 0.3650 - val_accuracy: 0.8280\n",
            "Epoch 845/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8400 - val_loss: 0.3674 - val_accuracy: 0.8340\n",
            "Epoch 846/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8400 - val_loss: 0.3671 - val_accuracy: 0.8340\n",
            "Epoch 847/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8400 - val_loss: 0.3679 - val_accuracy: 0.8360\n",
            "Epoch 848/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8467 - val_loss: 0.3659 - val_accuracy: 0.8340\n",
            "Epoch 849/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8487 - val_loss: 0.3654 - val_accuracy: 0.8280\n",
            "Epoch 850/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8433 - val_loss: 0.3664 - val_accuracy: 0.8340\n",
            "Epoch 851/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8427 - val_loss: 0.3659 - val_accuracy: 0.8420\n",
            "Epoch 852/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8360 - val_loss: 0.3685 - val_accuracy: 0.8260\n",
            "Epoch 853/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8400 - val_loss: 0.3652 - val_accuracy: 0.8340\n",
            "Epoch 854/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8400 - val_loss: 0.3654 - val_accuracy: 0.8400\n",
            "Epoch 855/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8447 - val_loss: 0.3653 - val_accuracy: 0.8360\n",
            "Epoch 856/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8427 - val_loss: 0.3673 - val_accuracy: 0.8240\n",
            "Epoch 857/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8433 - val_loss: 0.3669 - val_accuracy: 0.8280\n",
            "Epoch 858/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8373 - val_loss: 0.3650 - val_accuracy: 0.8320\n",
            "Epoch 859/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8447 - val_loss: 0.3671 - val_accuracy: 0.8300\n",
            "Epoch 860/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8447 - val_loss: 0.3639 - val_accuracy: 0.8340\n",
            "Epoch 861/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8427 - val_loss: 0.3664 - val_accuracy: 0.8300\n",
            "Epoch 862/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8387 - val_loss: 0.3707 - val_accuracy: 0.8260\n",
            "Epoch 863/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8467 - val_loss: 0.3661 - val_accuracy: 0.8260\n",
            "Epoch 864/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8447 - val_loss: 0.3665 - val_accuracy: 0.8400\n",
            "Epoch 865/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8400 - val_loss: 0.3680 - val_accuracy: 0.8260\n",
            "Epoch 866/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8380 - val_loss: 0.3672 - val_accuracy: 0.8320\n",
            "Epoch 867/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8467 - val_loss: 0.3680 - val_accuracy: 0.8320\n",
            "Epoch 868/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8333 - val_loss: 0.3647 - val_accuracy: 0.8340\n",
            "Epoch 869/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8433 - val_loss: 0.3669 - val_accuracy: 0.8400\n",
            "Epoch 870/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8460 - val_loss: 0.3669 - val_accuracy: 0.8380\n",
            "Epoch 871/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8433 - val_loss: 0.3730 - val_accuracy: 0.8240\n",
            "Epoch 872/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8327 - val_loss: 0.3699 - val_accuracy: 0.8360\n",
            "Epoch 873/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8360 - val_loss: 0.3671 - val_accuracy: 0.8320\n",
            "Epoch 874/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8480 - val_loss: 0.3647 - val_accuracy: 0.8380\n",
            "Epoch 875/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8420 - val_loss: 0.3665 - val_accuracy: 0.8280\n",
            "Epoch 876/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8393 - val_loss: 0.3699 - val_accuracy: 0.8400\n",
            "Epoch 877/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8440 - val_loss: 0.3701 - val_accuracy: 0.8320\n",
            "Epoch 878/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8407 - val_loss: 0.3660 - val_accuracy: 0.8320\n",
            "Epoch 879/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8380 - val_loss: 0.3731 - val_accuracy: 0.8280\n",
            "Epoch 880/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8433 - val_loss: 0.3671 - val_accuracy: 0.8340\n",
            "Epoch 881/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8453 - val_loss: 0.3682 - val_accuracy: 0.8320\n",
            "Epoch 882/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8433 - val_loss: 0.3682 - val_accuracy: 0.8300\n",
            "Epoch 883/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8433 - val_loss: 0.3656 - val_accuracy: 0.8300\n",
            "Epoch 884/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8433 - val_loss: 0.3688 - val_accuracy: 0.8380\n",
            "Epoch 885/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8380 - val_loss: 0.3661 - val_accuracy: 0.8400\n",
            "Epoch 886/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8473 - val_loss: 0.3677 - val_accuracy: 0.8400\n",
            "Epoch 887/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8373 - val_loss: 0.3688 - val_accuracy: 0.8300\n",
            "Epoch 888/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8440 - val_loss: 0.3657 - val_accuracy: 0.8380\n",
            "Epoch 889/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8393 - val_loss: 0.3750 - val_accuracy: 0.8240\n",
            "Epoch 890/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8440 - val_loss: 0.3678 - val_accuracy: 0.8360\n",
            "Epoch 891/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8380 - val_loss: 0.3651 - val_accuracy: 0.8320\n",
            "Epoch 892/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8427 - val_loss: 0.3672 - val_accuracy: 0.8280\n",
            "Epoch 893/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8440 - val_loss: 0.3662 - val_accuracy: 0.8380\n",
            "Epoch 894/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8393 - val_loss: 0.3683 - val_accuracy: 0.8380\n",
            "Epoch 895/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8367 - val_loss: 0.3667 - val_accuracy: 0.8340\n",
            "Epoch 896/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8420 - val_loss: 0.3628 - val_accuracy: 0.8300\n",
            "Epoch 897/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8433 - val_loss: 0.3692 - val_accuracy: 0.8320\n",
            "Epoch 898/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8433 - val_loss: 0.3715 - val_accuracy: 0.8240\n",
            "Epoch 899/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8440 - val_loss: 0.3642 - val_accuracy: 0.8420\n",
            "Epoch 900/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8447 - val_loss: 0.3684 - val_accuracy: 0.8380\n",
            "Epoch 901/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8380 - val_loss: 0.3677 - val_accuracy: 0.8360\n",
            "Epoch 902/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8460 - val_loss: 0.3643 - val_accuracy: 0.8220\n",
            "Epoch 903/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8447 - val_loss: 0.3660 - val_accuracy: 0.8400\n",
            "Epoch 904/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8473 - val_loss: 0.3670 - val_accuracy: 0.8220\n",
            "Epoch 905/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8413 - val_loss: 0.3684 - val_accuracy: 0.8380\n",
            "Epoch 906/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8393 - val_loss: 0.3675 - val_accuracy: 0.8380\n",
            "Epoch 907/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8400 - val_loss: 0.3657 - val_accuracy: 0.8360\n",
            "Epoch 908/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8447 - val_loss: 0.3672 - val_accuracy: 0.8360\n",
            "Epoch 909/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8420 - val_loss: 0.3694 - val_accuracy: 0.8420\n",
            "Epoch 910/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8427 - val_loss: 0.3705 - val_accuracy: 0.8280\n",
            "Epoch 911/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8367 - val_loss: 0.3677 - val_accuracy: 0.8340\n",
            "Epoch 912/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8400 - val_loss: 0.3671 - val_accuracy: 0.8360\n",
            "Epoch 913/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8387 - val_loss: 0.3674 - val_accuracy: 0.8400\n",
            "Epoch 914/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8407 - val_loss: 0.3664 - val_accuracy: 0.8440\n",
            "Epoch 915/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.8407 - val_loss: 0.3671 - val_accuracy: 0.8320\n",
            "Epoch 916/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8373 - val_loss: 0.3682 - val_accuracy: 0.8380\n",
            "Epoch 917/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8447 - val_loss: 0.3670 - val_accuracy: 0.8340\n",
            "Epoch 918/1000\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8400 - val_loss: 0.3706 - val_accuracy: 0.8320\n",
            "Epoch 919/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8473 - val_loss: 0.3685 - val_accuracy: 0.8360\n",
            "Epoch 920/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8460 - val_loss: 0.3687 - val_accuracy: 0.8300\n",
            "Epoch 921/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8387 - val_loss: 0.3677 - val_accuracy: 0.8340\n",
            "Epoch 922/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8433 - val_loss: 0.3670 - val_accuracy: 0.8300\n",
            "Epoch 923/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8447 - val_loss: 0.3677 - val_accuracy: 0.8320\n",
            "Epoch 924/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8420 - val_loss: 0.3691 - val_accuracy: 0.8340\n",
            "Epoch 925/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8420 - val_loss: 0.3691 - val_accuracy: 0.8260\n",
            "Epoch 926/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8453 - val_loss: 0.3680 - val_accuracy: 0.8360\n",
            "Epoch 927/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8467 - val_loss: 0.3661 - val_accuracy: 0.8280\n",
            "Epoch 928/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8480 - val_loss: 0.3711 - val_accuracy: 0.8380\n",
            "Epoch 929/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3474 - accuracy: 0.8373 - val_loss: 0.3694 - val_accuracy: 0.8280\n",
            "Epoch 930/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8473 - val_loss: 0.3693 - val_accuracy: 0.8320\n",
            "Epoch 931/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8427 - val_loss: 0.3672 - val_accuracy: 0.8360\n",
            "Epoch 932/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8447 - val_loss: 0.3690 - val_accuracy: 0.8300\n",
            "Epoch 933/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8433 - val_loss: 0.3756 - val_accuracy: 0.8180\n",
            "Epoch 934/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8373 - val_loss: 0.3711 - val_accuracy: 0.8420\n",
            "Epoch 935/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8413 - val_loss: 0.3676 - val_accuracy: 0.8300\n",
            "Epoch 936/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8453 - val_loss: 0.3723 - val_accuracy: 0.8200\n",
            "Epoch 937/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8447 - val_loss: 0.3721 - val_accuracy: 0.8380\n",
            "Epoch 938/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8373 - val_loss: 0.3695 - val_accuracy: 0.8240\n",
            "Epoch 939/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8413 - val_loss: 0.3689 - val_accuracy: 0.8340\n",
            "Epoch 940/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8373 - val_loss: 0.3725 - val_accuracy: 0.8340\n",
            "Epoch 941/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8393 - val_loss: 0.3683 - val_accuracy: 0.8420\n",
            "Epoch 942/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8360 - val_loss: 0.3738 - val_accuracy: 0.8360\n",
            "Epoch 943/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8473 - val_loss: 0.3692 - val_accuracy: 0.8280\n",
            "Epoch 944/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8400 - val_loss: 0.3724 - val_accuracy: 0.8220\n",
            "Epoch 945/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8420 - val_loss: 0.3663 - val_accuracy: 0.8480\n",
            "Epoch 946/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8433 - val_loss: 0.3703 - val_accuracy: 0.8340\n",
            "Epoch 947/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8467 - val_loss: 0.3715 - val_accuracy: 0.8260\n",
            "Epoch 948/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8460 - val_loss: 0.3691 - val_accuracy: 0.8420\n",
            "Epoch 949/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8473 - val_loss: 0.3694 - val_accuracy: 0.8320\n",
            "Epoch 950/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8453 - val_loss: 0.3689 - val_accuracy: 0.8460\n",
            "Epoch 951/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8393 - val_loss: 0.3684 - val_accuracy: 0.8340\n",
            "Epoch 952/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8360 - val_loss: 0.3676 - val_accuracy: 0.8440\n",
            "Epoch 953/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8427 - val_loss: 0.3679 - val_accuracy: 0.8460\n",
            "Epoch 954/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8453 - val_loss: 0.3719 - val_accuracy: 0.8200\n",
            "Epoch 955/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8427 - val_loss: 0.3681 - val_accuracy: 0.8400\n",
            "Epoch 956/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8433 - val_loss: 0.3694 - val_accuracy: 0.8420\n",
            "Epoch 957/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8440 - val_loss: 0.3689 - val_accuracy: 0.8420\n",
            "Epoch 958/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8407 - val_loss: 0.3738 - val_accuracy: 0.8340\n",
            "Epoch 959/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8407 - val_loss: 0.3702 - val_accuracy: 0.8380\n",
            "Epoch 960/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8427 - val_loss: 0.3691 - val_accuracy: 0.8400\n",
            "Epoch 961/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8400 - val_loss: 0.3704 - val_accuracy: 0.8320\n",
            "Epoch 962/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8440 - val_loss: 0.3701 - val_accuracy: 0.8500\n",
            "Epoch 963/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8453 - val_loss: 0.3697 - val_accuracy: 0.8400\n",
            "Epoch 964/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8427 - val_loss: 0.3717 - val_accuracy: 0.8400\n",
            "Epoch 965/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8407 - val_loss: 0.3707 - val_accuracy: 0.8440\n",
            "Epoch 966/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8433 - val_loss: 0.3695 - val_accuracy: 0.8380\n",
            "Epoch 967/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8453 - val_loss: 0.3704 - val_accuracy: 0.8400\n",
            "Epoch 968/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8467 - val_loss: 0.3717 - val_accuracy: 0.8420\n",
            "Epoch 969/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8360 - val_loss: 0.3692 - val_accuracy: 0.8440\n",
            "Epoch 970/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8433 - val_loss: 0.3711 - val_accuracy: 0.8480\n",
            "Epoch 971/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8427 - val_loss: 0.3692 - val_accuracy: 0.8380\n",
            "Epoch 972/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8387 - val_loss: 0.3718 - val_accuracy: 0.8480\n",
            "Epoch 973/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8407 - val_loss: 0.3724 - val_accuracy: 0.8320\n",
            "Epoch 974/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8407 - val_loss: 0.3707 - val_accuracy: 0.8440\n",
            "Epoch 975/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8520 - val_loss: 0.3691 - val_accuracy: 0.8460\n",
            "Epoch 976/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8413 - val_loss: 0.3723 - val_accuracy: 0.8260\n",
            "Epoch 977/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8387 - val_loss: 0.3715 - val_accuracy: 0.8340\n",
            "Epoch 978/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8487 - val_loss: 0.3719 - val_accuracy: 0.8500\n",
            "Epoch 979/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8400 - val_loss: 0.3731 - val_accuracy: 0.8300\n",
            "Epoch 980/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8433 - val_loss: 0.3720 - val_accuracy: 0.8440\n",
            "Epoch 981/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.8400 - val_loss: 0.3705 - val_accuracy: 0.8400\n",
            "Epoch 982/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8427 - val_loss: 0.3726 - val_accuracy: 0.8380\n",
            "Epoch 983/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8407 - val_loss: 0.3706 - val_accuracy: 0.8440\n",
            "Epoch 984/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8440 - val_loss: 0.3718 - val_accuracy: 0.8460\n",
            "Epoch 985/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8400 - val_loss: 0.3708 - val_accuracy: 0.8380\n",
            "Epoch 986/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8427 - val_loss: 0.3716 - val_accuracy: 0.8400\n",
            "Epoch 987/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8447 - val_loss: 0.3721 - val_accuracy: 0.8480\n",
            "Epoch 988/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8433 - val_loss: 0.3694 - val_accuracy: 0.8440\n",
            "Epoch 989/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8387 - val_loss: 0.3710 - val_accuracy: 0.8320\n",
            "Epoch 990/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8407 - val_loss: 0.3743 - val_accuracy: 0.8240\n",
            "Epoch 991/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8407 - val_loss: 0.3689 - val_accuracy: 0.8460\n",
            "Epoch 992/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8467 - val_loss: 0.3701 - val_accuracy: 0.8520\n",
            "Epoch 993/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8380 - val_loss: 0.3746 - val_accuracy: 0.8260\n",
            "Epoch 994/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8413 - val_loss: 0.3725 - val_accuracy: 0.8300\n",
            "Epoch 995/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8380 - val_loss: 0.3700 - val_accuracy: 0.8440\n",
            "Epoch 996/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8427 - val_loss: 0.3714 - val_accuracy: 0.8400\n",
            "Epoch 997/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8380 - val_loss: 0.3698 - val_accuracy: 0.8400\n",
            "Epoch 998/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8427 - val_loss: 0.3700 - val_accuracy: 0.8420\n",
            "Epoch 999/1000\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8407 - val_loss: 0.3719 - val_accuracy: 0.8320\n",
            "Epoch 1000/1000\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8407 - val_loss: 0.3683 - val_accuracy: 0.8440\n"
          ]
        }
      ],
      "source": [
        "## Note that when we call \"fit\" again, it picks up where it left off\n",
        "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dGHWsvEYNd9U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "241f4c03-f356-4df2-bdcf-ec2514be0642"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ffa35df8a90>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCudnt2xNd9V"
      },
      "source": [
        "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "neural-networks-to-predict-diabetes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}